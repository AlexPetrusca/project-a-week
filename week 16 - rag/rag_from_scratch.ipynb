{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-13T02:57:26.233893Z",
     "start_time": "2025-07-13T02:57:26.230265Z"
    }
   },
   "source": "# Let's go about building RAG \"from scratch\"",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T02:57:26.247237Z",
     "start_time": "2025-07-13T02:57:26.240403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() # load environment variables"
   ],
   "id": "d93cadd4c3687007",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Part 1: Indexing",
   "id": "bdab1efe108f1d82"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T02:57:26.731685Z",
     "start_time": "2025-07-13T02:57:26.316911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Embed a question (query) and 2 documents using an embedding model\n",
    "\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "question = \"What kinds of pets do I like?\"\n",
    "document1 = \"My favorite pet is a cat.\"\n",
    "document2 = \"I went to Lake Tahoe last weekend.\"\n",
    "\n",
    "embed_model = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "question_embed = embed_model.embed_query(question)\n",
    "document1_embed = embed_model.embed_query(document1)\n",
    "document2_embed = embed_model.embed_query(document2)\n",
    "\n",
    "print(len(question_embed), len(document1_embed), len(document2_embed))"
   ],
   "id": "ba4e207feee7768d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 768 768\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T02:57:26.770240Z",
     "start_time": "2025-07-13T02:57:26.737444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use cosine similarity to test how related each document is to the query.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "similarity1 = cosine_similarity(question_embed, document1_embed)\n",
    "similarity2 = cosine_similarity(question_embed, document2_embed)\n",
    "\n",
    "print(\"Similarity to Document 1:\", similarity1)  # ~0.749: high similarity\n",
    "print(\"Similarity to Document 2:\", similarity2)  # ~0.445: lower similarity"
   ],
   "id": "e6961d748280f02d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity to Document 1: 0.7487750832631482\n",
      "Similarity to Document 2: 0.44519811332617293\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T02:57:28.292866Z",
     "start_time": "2025-07-13T02:57:26.781717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now that we have the general idea down, let's ingest documents from the internet. We will:\n",
    "#   - fetch a webpage's content (specifically, a blog post about \"LLM Powered Autonomous Agents\")\n",
    "#   - split the content into chunks; these will be our documents\n",
    "#   - embed these document and store them in a vector database (ChromaDB)\n",
    "\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Load blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "blog_docs = loader.load()\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=300, chunk_overlap=50) # uses tiktoken before splitting\n",
    "splits = text_splitter.split_documents(blog_docs)\n",
    "\n",
    "# Index\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OllamaEmbeddings(model=\"nomic-embed-text\"))\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "print(len(splits))  # 50 documents in our vector database"
   ],
   "id": "e7676f9b982bc4b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 2: Retrieval",
   "id": "88844276eb3d5b74"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T02:57:28.333112Z",
     "start_time": "2025-07-13T02:57:28.296770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's retrieve relevant documents based on our query\n",
    "\n",
    "docs = retriever.invoke(\"What is Task Decomposition?\")\n",
    "len(docs)"
   ],
   "id": "7ec6f9b9d3cb3698",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T02:57:28.348100Z",
     "start_time": "2025-07-13T02:57:28.345397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We can use these documents to form a context to pass alongside our query\n",
    "\n",
    "context = \"\"\n",
    "for doc in docs:\n",
    "    context += doc.page_content + \"\\n\\n\"\n",
    "\n",
    "print(context)"
   ],
   "id": "25e7d36f081c12a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "\n",
      "Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\n",
      "\n",
      "The paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\n",
      "In reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\n",
      "In comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.\n",
      "\n",
      "Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\n",
      "\n",
      "The system comprises of 4 stages:\n",
      "(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\n",
      "Instruction:\n",
      "\n",
      "The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can't be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\n",
      "\n",
      "Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\n",
      "\n",
      "In both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\n",
      "Reflexion (Shinn & Labash 2023) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\n",
      "\n",
      "\n",
      "Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 3: Generation",
   "id": "1fb24b67b0031288"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T02:57:28.363980Z",
     "start_time": "2025-07-13T02:57:28.355733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now, we create a prompt that takes both our retrieved context and user question\n",
    "\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template('''\n",
    "    You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "    Answer:\n",
    "''')\n",
    "prompt = prompt_template.invoke({\"context\": context, \"question\": \"What is Task Decomposition?\"})\n",
    "\n",
    "print(prompt)"
   ],
   "id": "a93f7424a2d0336a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='\\n    You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\\'t know the answer, just say that you don\\'t know. Use three sentences maximum and keep the answer concise.\\n    Context: Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\n\\nIllustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\n\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.\\n\\nIllustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\n\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:\\n\\nThe AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\nExamples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\n\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\\n\\n\\nIllustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\n\\n\\n    Question: What is Task Decomposition?\\n    Answer:\\n'\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T02:57:29.292473Z",
     "start_time": "2025-07-13T02:57:28.382076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Finally, we pass this prompt to the model. Congratulations! That's the basics of RAG.\n",
    "\n",
    "llm = OllamaLLM(model=\"llama3.2:1b\")\n",
    "llm.invoke(prompt)"
   ],
   "id": "fcd07d8f78c3b66b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Task decomposition refers to breaking down complex tasks into smaller and simpler steps for model training or improvement. It involves decomposing hard tasks into manageable parts using techniques such as Chain of Thought (CoT), Tree of Thoughts, Algorithm Distillation (AD), and HuggingGPT's Task Planning stages. The goal is to make the task more interpretable and easier to understand.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
