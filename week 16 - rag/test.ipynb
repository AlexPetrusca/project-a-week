{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-12T20:10:31.482721Z",
     "start_time": "2025-07-12T20:10:31.475388Z"
    }
   },
   "source": [
    "# load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T20:27:03.412097Z",
     "start_time": "2025-07-12T20:26:53.659701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = OllamaLLM(model=\"gemma3n\")\n",
    "chain = prompt | model\n",
    "\n",
    "response = chain.invoke({\"question\": \"What is LangChain?\"})\n",
    "print(response)"
   ],
   "id": "4855aee5771fa497",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's think step by step about what LangChain is. \n",
      "\n",
      "LangChain is essentially a framework designed to simplify the development of applications powered by large language models (LLMs). Think of it as a toolkit that provides components and chains to help you connect LLMs to other sources of data and to each other.\n",
      "\n",
      "Here's a more detailed breakdown:\n",
      "\n",
      "* **LLM Focus:** It's built specifically to work with LLMs like GPT-3, GPT-4, and open-source models.\n",
      "* **Chains:** The core concept is \"chains,\" which are sequences of calls to different components. These chains allow you to build complex workflows. For example, a chain might first retrieve relevant documents from a database, then feed those documents to an LLM to answer a question.\n",
      "* **Components:** LangChain provides a wide range of components, including:\n",
      "    * **Models:** Interfaces for different LLMs.\n",
      "    * **Prompts:** Tools for crafting effective prompts to guide the LLM.\n",
      "    * **Indexes:**  Ways to structure and retrieve data for use with LLMs (e.g., document loaders, text splitters, vector stores).\n",
      "    * **Memory:**  Mechanisms to add conversational memory to your LLM applications.\n",
      "    * **Agents:**  Systems that use an LLM to decide which actions to take, allowing them to interact with external tools.\n",
      "* **Use Cases:** LangChain is used for a variety of applications, such as:\n",
      "    * **Question Answering:** Building systems that can answer questions based on your own data.\n",
      "    * **Chatbots:** Creating more sophisticated and context-aware chatbots.\n",
      "    * **Document Summarization:**  Automatically summarizing long documents.\n",
      "    * **Data Extraction:**  Extracting structured data from unstructured text.\n",
      "    * **Agent-based applications:** Creating autonomous agents that can perform tasks.\n",
      "\n",
      "In short, LangChain makes it easier to build powerful and flexible applications that leverage the capabilities of large language models. It abstracts away a lot of the complexity involved in interacting with LLMs and connecting them to other systems.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
