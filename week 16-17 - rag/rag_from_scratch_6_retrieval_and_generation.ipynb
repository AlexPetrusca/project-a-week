{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrieval is the process of fetching relevant information from an external data source (like a document database or vector store) to help a language model generate more accurate, grounded, and context-aware responses.\n",
    "# Generation is the final step where a language model creates a response based on the user query and the documents retrieved from the knowledge base."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() # load environment variables"
   ],
   "id": "2ab523b67bfbdacb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Problem Statement\n",
    "\n",
    "**Retrieval** is a critical step in RAG pipelines. If the retriever fails to surface relevant documents, the **generation** stage will be starved of the context it needs — even if the answer exists somewhere in the data.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "User query:\n",
    "- “Can I bring my dog on the plane?”\n",
    "\n",
    "Problem:\n",
    "- The relevant document says: “Small pets are allowed in the cabin if kept in an airline-approved carrier.”\n",
    "- The word “dog” never appears — only “pets” or “animals.”\n",
    "\n",
    "Retrieval Failure:\n",
    "- A naive retriever might not consider “dog” and “pet” semantically similar.\n",
    "- The relevant document is not retrieved, even though it answers the question.\n",
    "\n",
    "Result:\n",
    "- The LLM, lacking the key passage, responds: “I couldn’t find any information about dogs on the plane.”\n",
    "- Users perceive this as a model failure, but the real issue was the retriever’s blind spot."
   ],
   "id": "11ae376c6747971f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Strategy #1: Ranking\n",
    "\n",
    "![Image](rsc/jupyter/rag-fusion.png)\n",
    "\n",
    "**Idea**: Post-processing step where the initial set of retrieved documents is re-scored and re-ordered based on how relevant they are to the user’s query — typically using a more powerful model than was used during initial retrieval.\n",
    "\n",
    "---\n",
    "\n",
    "Three strategies that use this idea:\n",
    "- **Re-Rank**: Score and reorder initially retrieved documents using a query-document relevance model (e.g., a cross-encoder).\n",
    "- **RankGPT**: Use a language model itself to rank candidate documents by how well they answer the query — using generation and reasoning rather than embeddings.\n",
    "- **RAG-Fusion**: Run multiple diverse queries (original + variations) through the retriever, then fuse the results for better coverage (we covered this in \"query translation\")."
   ],
   "id": "4b1a576745950605"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bca8a96d765a98e6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Strategy #2: CRAG\n",
    "\n",
    "![Image](rsc/jupyter/crag.png)\n",
    "\n",
    "**Idea**: The language model identifies and corrects retrieval errors during generation — essentially giving itself a second chance if the first retrieval step was inadequate."
   ],
   "id": "ab2886bd08d315e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6ed5788a3b085edd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Strategy #3: Self-RAG\n",
    "\n",
    "![Image](rsc/jupyter/self-rag.png)\n",
    "\n",
    "**Idea**: The language model itself actively critiques and improves its own retrieval process, often by reformulating the query, selecting better documents, or rerunning retrieval — all within a single inference loop."
   ],
   "id": "e8ce2de0058511c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "source": "",
   "id": "55dc66b05406f1ec",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
