{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T08:03:29.454511Z",
     "start_time": "2025-03-01T08:03:29.452137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import mlx.core as mx\n",
    "import mlx.nn as nn"
   ],
   "id": "6e2b5de1316f87db",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T08:05:18.081324Z",
     "start_time": "2025-03-01T08:05:18.078650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create input tensor and layer\n",
    "x = mx.random.normal((1, 10))  # Example input\n",
    "layer = nn.Linear(10, 5)  # Example layer"
   ],
   "id": "77bc2e79cf5973c1",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T08:05:21.600294Z",
     "start_time": "2025-03-01T08:05:21.596951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a function to compute loss (example: sum of outputs)\n",
    "def loss_fn(x, layer):\n",
    "    y = layer(x)\n",
    "    return mx.sum(y)"
   ],
   "id": "5741f58dede10f9c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T08:05:23.382197Z",
     "start_time": "2025-03-01T08:05:23.378378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute the gradient of loss with respect to inputs\n",
    "grad_fn = mx.grad(loss_fn, argnums=0)  # For input gradient\n",
    "dx = grad_fn(x, layer)\n",
    "print(dx)"
   ],
   "id": "758cbeec6abae07a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[-0.436604, 0.352889, -0.0173761, ..., -0.217485, 0.145848, 0.752257]], dtype=float32)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T08:05:25.684630Z",
     "start_time": "2025-03-01T08:05:25.674027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute the gradient of loss with respect to layer parameters\n",
    "grad_fn_params = mx.grad(loss_fn, argnums=1)  # For layer parameter gradients\n",
    "dlayer = grad_fn_params(x, layer)\n",
    "print(dlayer)"
   ],
   "id": "a74064746391572a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weight': array([[1.00744, -0.594229, -0.660508, ..., -1.24775, 0.0335962, -1.0371],\n",
      "       [1.00744, -0.594229, -0.660508, ..., -1.24775, 0.0335962, -1.0371],\n",
      "       [1.00744, -0.594229, -0.660508, ..., -1.24775, 0.0335962, -1.0371],\n",
      "       [1.00744, -0.594229, -0.660508, ..., -1.24775, 0.0335962, -1.0371],\n",
      "       [1.00744, -0.594229, -0.660508, ..., -1.24775, 0.0335962, -1.0371]], dtype=float32), 'bias': array([1, 1, 1, 1, 1], dtype=float32)}\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bd92a355737a1080"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
