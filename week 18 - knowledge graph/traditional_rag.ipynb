{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-06T20:22:44.408255Z",
     "start_time": "2025-08-06T20:22:44.406165Z"
    }
   },
   "source": "# Let's perform traditional RAG on a mock Obsidian vault",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T20:22:44.482827Z",
     "start_time": "2025-08-06T20:22:44.477525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # load environment variables"
   ],
   "id": "8f1681d311d23694",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T20:22:48.385467Z",
     "start_time": "2025-08-06T20:22:44.487603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Indexing: Let's load our full documents\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(\"./\", glob=\"**/*.md\", show_progress=True, use_multithreading=True)\n",
    "\n",
    "full_documents = loader.load()\n",
    "full_documents[0]"
   ],
   "id": "3c856c4acdf1543d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/66 [00:00<?, ?it/s]Need to load profiles.\n",
      "Need to load profiles.\n",
      "Need to load profiles.\n",
      "Need to load profiles.\n",
      "Need to load profiles.\n",
      "short text: \"![[priority_queue_overview.png|500]]\". Defaulting to English.\n",
      "short text: \"Example\". Defaulting to English.\n",
      "short text: \"Multiply by two:\". Defaulting to English.\n",
      "short text: \"Operations\". Defaulting to English.\n",
      "short text: \"https://leetcode.com/problems/minimum-height-trees/\". Defaulting to English.\n",
      "short text: \"x <<= 1\". Defaulting to English.\n",
      "short text: \"%%\". Defaulting to English.\n",
      "short text: \"Divide by two:\". Defaulting to English.\n",
      "short text: \"stub\". Defaulting to English.\n",
      "short text: \"Applications\". Defaulting to English.\n",
      "short text: \"x >>= 1\". Defaulting to English.\n",
      "  2%|▏         | 1/66 [00:02<02:31,  2.32s/it]short text: \"%%\". Defaulting to English.\n",
      "short text: \"Swap two numbers:\". Defaulting to English.\n",
      "short text: \"![[algo_seam_carving_overview.png]]\". Defaulting to English.\n",
      "short text: \"How It Works\". Defaulting to English.\n",
      "short text: \"Complexity Analysis\". Defaulting to English.\n",
      "short text: \"Energy Map Creation\". Defaulting to English.\n",
      "short text: \"Structure\". Defaulting to English.\n",
      "short text: \"Seam Identification\". Defaulting to English.\n",
      "short text: \"![[union_find_structure.png|500]]\". Defaulting to English.\n",
      "short text: \"Operation\". Defaulting to English.\n",
      "  8%|▊         | 5/66 [00:02<00:23,  2.57it/s]short text: \"![[union_find_operations.png]]\". Defaulting to English.\n",
      "short text: \"Implementation\". Defaulting to English.\n",
      "short text: \"Seam Removal or Insertion\". Defaulting to English.\n",
      "short text: \"Path Compression\". Defaulting to English.\n",
      "short text: \"Pros / Cons\". Defaulting to English.\n",
      "short text: \"Applications\". Defaulting to English.\n",
      "short text: \"![[sorting_network_overview.png]]\". Defaulting to English.\n",
      "short text: \"Path Halving\". Defaulting to English.\n",
      "short text: \"Zero-One Principle\". Defaulting to English.\n",
      "short text: \"Parallelism\". Defaulting to English.\n",
      "short text: \"Complexity Analysis\". Defaulting to English.\n",
      "short text: \"Edge List\". Defaulting to English.\n",
      " 11%|█         | 7/66 [00:02<00:18,  3.24it/s]short text: \"![[sorting_network_insertion_sort.png|400]]\". Defaulting to English.\n",
      "short text: \"Adjacency Matrix\". Defaulting to English.\n",
      "short text: \"Bitonic Mergesort\". Defaulting to English.\n",
      "short text: \"Adjacency List\". Defaulting to English.\n",
      "short text: \"![[sorting_network_bitonic_sort_directional.png]]\". Defaulting to English.\n",
      "short text: \"Adjacency Sets\". Defaulting to English.\n",
      "short text: \"![[sorting_network_bitonic_sort.png]]\". Defaulting to English.\n",
      "short text: \"%% stub %%\". Defaulting to English.\n",
      "short text: \"![[sorting_network_batcher_odd_even_mergesort.png|400]]\". Defaulting to English.\n",
      "short text: \"Applications\". Defaulting to English.\n",
      " 32%|███▏      | 21/66 [00:03<00:02, 20.97it/s]short text: \"%% stub %%\". Defaulting to English.\n",
      "short text: \"%%\". Defaulting to English.\n",
      "short text: \"stub # todo\". Defaulting to English.\n",
      "short text: \"%%\". Defaulting to English.\n",
      "short text: \"%% stub %%\". Defaulting to English.\n",
      " 41%|████      | 27/66 [00:03<00:04,  8.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'rsc/vault/Priority Queue.md'}, page_content='A priority queue is an abstract data structure, similar to a queue, in which each element has an associated priority and elements with high priority are served before elements with low priority.\\n\\n![[priority_queue_overview.png|500]]\\n\\nPriority queues are commonly implemented using [[Heap|heaps]], giving $O(\\\\log n)$ performance for inserts and removals, and $O(n)$ to build the heap initially from a set of $n$ elements.\\n\\nOperations\\n\\nPriority queues support the following operations:\\n\\nBasic - enqueue: add an element to the queue with an associated priority. - dequeue: remove the highest priority element from the queue, and return it. - delete: remove an element from the queue. - peek: return the highest priority element from the queue.\\n\\nInspection - size: return the number of elements in the queue. - is_empty: check whether the queue has no elements.\\n\\nEquivalence of priority queues and sorting algorithms\\n\\nThe semantics of priority queues naturally suggest a sorting method: 1. insert all the elements to be sorted into a priority queue 2. sequentially remove them; they will come out in sorted order.\\n\\nName Priority Queue Implementation Best Average Worst [[Heapsort]] Heap $n \\\\log n$ $n \\\\log n$ $n \\\\log n$ Smoothsort Leonardo Heap $n$ $n \\\\log n$ $n \\\\log n$ Selection sort Unordered Array {.bad-cell}$n^2$ {.bad-cell}$n^2$ {.bad-cell}$n^2$ [[Insertion sort]] Ordered Array $n$ {.bad-cell}$n^2$ {.bad-cell}$n^2$ Tree sort Self-balancing binary search tree $n \\\\log n$ $n \\\\log n$ $n \\\\log n$\\n\\nA sorting algorithm can also be used to implement a priority queue. If we can sort up to $n$ keys in $S(n)$ time per key, then there is a priority queue supporting enqueue, dequeue, and delete in $O(S(n))$ time and peek in constant time. - For example, if one has an $O(n \\\\log n)$ sort algorithm, one can create a priority queue with $O(1)$ polling and $O(\\\\log n)$ insertion.\\n\\nApplications\\n\\nGenerally, priority queues share the same applications as heaps (see [[Heap#Applications]]).')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T20:22:50.351244Z",
     "start_time": "2025-08-06T20:22:48.396900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Indexing: Let's chunk and insert our documents into FAISS\n",
    "\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=64)\n",
    "documents = text_splitter.split_documents(full_documents)\n",
    "\n",
    "# store in FAISS with nomic embeddings (ollama)\n",
    "embedding_model = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "vectorstore = FAISS.from_documents(documents=documents, embedding=embedding_model)\n",
    "\n",
    "documents[0]"
   ],
   "id": "152b0523d18633b9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'rsc/vault/Priority Queue.md'}, page_content='A priority queue is an abstract data structure, similar to a queue, in which each element has an associated priority and elements with high priority are served before elements with low priority.\\n\\n![[priority_queue_overview.png|500]]\\n\\nPriority queues are commonly implemented using [[Heap|heaps]], giving $O(\\\\log n)$ performance for inserts and removals, and $O(n)$ to build the heap initially from a set of $n$ elements.\\n\\nOperations\\n\\nPriority queues support the following operations:')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T20:22:50.362524Z",
     "start_time": "2025-08-06T20:22:50.360342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a query\n",
    "\n",
    "# query = \"Given an integer array nums, handle multiple queries of the following types: 1. Update the value of an element in nums. 2. Calculate the sum of the elements of nums between indices left and right inclusive where left <= right. Give a broad strokes overview of how you'd solve this?\"\n",
    "\n",
    "# query = \"What data structures and algorithms do you use to solve the trapping rainwater coding problem?\"\n",
    "\n",
    "# query = \"What is a fenwick tree?\"\n",
    "\n",
    "# query = \"What is the seam carving algorithm?\"\n",
    "\n",
    "# query = \"What is a multiset good for?\"\n",
    "\n",
    "query = \"What is the relationship between a prefix sum and an integral image?\""
   ],
   "id": "d316ab6d819dbacd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T20:22:51.119392Z",
     "start_time": "2025-08-06T20:22:50.371422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retrieval and generation: Let's set up a RAG chain\n",
    "\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template('''\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. A longer answer isn't necessarily better. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "''')\n",
    "\n",
    "llm = OllamaLLM(model=\"llama3.2:1b\")\n",
    "\n",
    "rag_chain = (\n",
    "        {\n",
    "            \"context\": vectorstore.as_retriever(),\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_response = rag_chain.invoke(query)\n",
    "print(rag_response)"
   ],
   "id": "84155e055c78f0ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A prefix sum and an integral image share the same underlying operation, which involves calculating the sum of elements up to a given index in both cases. In a prefix sum, this is typically done using a simple loop that sums adjacent elements; in an integral image, it's achieved by iteratively adding pixels above and to the left of each pixel.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T20:22:51.601310Z",
     "start_time": "2025-08-06T20:22:51.127396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's set up a simple chain to test our RAG against\n",
    "\n",
    "simple_prompt = PromptTemplate.from_template('''\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "Question: {question}\n",
    "Answer:\n",
    "''')\n",
    "simple_chain = simple_prompt | llm | StrOutputParser()\n",
    "\n",
    "simple_response = simple_chain.invoke(query)\n",
    "print(simple_response)"
   ],
   "id": "cb4eea0754a2d4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A prefix sum in the context of integers, particularly in binary arithmetic, calculates the weighted average of a set of digits. This process involves converting each digit into its equivalent value based on powers of 2 (e.g., 1 = 2^0, 10 = 2^1). The result is then added together to form the final integer sum.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T20:22:53.683536Z",
     "start_time": "2025-08-06T20:22:51.613011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use a stronger LLM to judge which response is better\n",
    "\n",
    "judge_prompt = PromptTemplate.from_template('''\n",
    "You will be given a question and two different answers to that question. Based on your knowledge, judge which answer is better, in terms of factual accuracy and relevance to the question. If they are about the same, then say so. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Question: {question}\n",
    "Answer1: {answer1}\n",
    "Answer2: {answer2}\n",
    "\n",
    "Your response:\n",
    "''')\n",
    "judge_chain = (\n",
    "        judge_prompt\n",
    "        | OllamaLLM(model=\"gemma3n\")\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "judge_response = judge_chain.invoke({\n",
    "    \"question\": query,\n",
    "    \"answer1\": rag_response,\n",
    "    \"answer2\": simple_response,\n",
    "})\n",
    "print(judge_response)"
   ],
   "id": "ce8ef6c840144e13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer1 is better because it accurately describes the core relationship between prefix sums and integral images: both compute cumulative sums. Answer2 describes a prefix sum in the context of weighted averages and binary arithmetic, which is not the primary connection to integral images and therefore less relevant.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
