{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-06T17:39:09.108877Z",
     "start_time": "2025-08-06T17:39:09.106677Z"
    }
   },
   "source": "# Let's perform traditional rag on a mock Obsidian vault",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T17:39:09.124391Z",
     "start_time": "2025-08-06T17:39:09.116088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # load environment variables"
   ],
   "id": "8f1681d311d23694",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T17:39:13.107298Z",
     "start_time": "2025-08-06T17:39:09.232085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Indexing: Let's load our full documents\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(\"./\", glob=\"**/*.md\", show_progress=True, use_multithreading=True)\n",
    "\n",
    "full_documents = loader.load()\n",
    "full_documents[0]"
   ],
   "id": "3c856c4acdf1543d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/66 [00:02<01:29,  1.40s/it]short text: \"Multiply by two:\". Defaulting to English.\n",
      "short text: \"x <<= 1\". Defaulting to English.\n",
      "short text: \"Divide by two:\". Defaulting to English.\n",
      "short text: \"x >>= 1\". Defaulting to English.\n",
      "short text: \"Swap two numbers:\". Defaulting to English.\n",
      "short text: \"Complexity Analysis\". Defaulting to English.\n",
      "  9%|▉         | 6/66 [00:02<00:28,  2.11it/s]short text: \"Structure\". Defaulting to English.\n",
      "short text: \"![[sorting_network_overview.png]]\". Defaulting to English.\n",
      "short text: \"Operation\". Defaulting to English.\n",
      "short text: \"Construct\". Defaulting to English.\n",
      "short text: \"Zero-One Principle\". Defaulting to English.\n",
      "short text: \"Query Range\". Defaulting to English.\n",
      "short text: \"Edge List\". Defaulting to English.\n",
      "short text: \"Parallelism\". Defaulting to English.\n",
      "short text: \"Update\". Defaulting to English.\n",
      "short text: \"Adjacency Matrix\". Defaulting to English.\n",
      "short text: \"Complexity Analysis\". Defaulting to English.\n",
      "short text: \"Variants\". Defaulting to English.\n",
      "short text: \"Adjacency List\". Defaulting to English.\n",
      "short text: \"![[sorting_network_insertion_sort.png|400]]\". Defaulting to English.\n",
      "short text: \"Adjacency Sets\". Defaulting to English.\n",
      "short text: \"Bitonic Mergesort\". Defaulting to English.\n",
      " 12%|█▏        | 8/66 [00:02<00:20,  2.82it/s]short text: \"![[sorting_network_bitonic_sort_directional.png]]\". Defaulting to English.\n",
      "short text: \"![[sorting_network_bitonic_sort.png]]\". Defaulting to English.\n",
      "short text: \"![[cs_ds_multimap.png]]\". Defaulting to English.\n",
      "short text: \"%% stub %%\". Defaulting to English.\n",
      "short text: \"Language Support\". Defaulting to English.\n",
      "short text: \"![[sorting_network_batcher_odd_even_mergesort.png|400]]\". Defaulting to English.\n",
      "short text: \"Applications\". Defaulting to English.\n",
      "short text: \"Applications\". Defaulting to English.\n",
      " 15%|█▌        | 10/66 [00:02<00:15,  3.51it/s]short text: \"![[hash_table_overview.png]]\". Defaulting to English.\n",
      "short text: \"Complexity Analysis\". Defaulting to English.\n",
      "short text: \"Collision Resolution\". Defaulting to English.\n",
      "short text: \"Dynamic resizing\". Defaulting to English.\n",
      "short text: \"Hash Function\". Defaulting to English.\n",
      " 23%|██▎       | 15/66 [00:03<00:07,  6.68it/s]short text: \"Applications\". Defaulting to English.\n",
      " 27%|██▋       | 18/66 [00:03<00:02, 16.34it/s]short text: \"%%\". Defaulting to English.\n",
      "short text: \"stub # todo\". Defaulting to English.\n",
      "short text: \"%%\". Defaulting to English.\n",
      "short text: \"%% stub %%\". Defaulting to English.\n",
      " 36%|███▋      | 24/66 [00:03<00:01, 21.69it/s]short text: \"%% stub %%\". Defaulting to English.\n",
      " 41%|████      | 27/66 [00:03<00:04,  8.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'rsc/vault/Priority Queue.md'}, page_content='A priority queue is an abstract data structure, similar to a queue, in which each element has an associated priority and elements with high priority are served before elements with low priority.\\n\\n![[priority_queue_overview.png|500]]\\n\\nPriority queues are commonly implemented using [[Heap|heaps]], giving $O(\\\\log n)$ performance for inserts and removals, and $O(n)$ to build the heap initially from a set of $n$ elements.\\n\\nOperations\\n\\nPriority queues support the following operations:\\n\\nBasic - enqueue: add an element to the queue with an associated priority. - dequeue: remove the highest priority element from the queue, and return it. - delete: remove an element from the queue. - peek: return the highest priority element from the queue.\\n\\nInspection - size: return the number of elements in the queue. - is_empty: check whether the queue has no elements.\\n\\nEquivalence of priority queues and sorting algorithms\\n\\nThe semantics of priority queues naturally suggest a sorting method: 1. insert all the elements to be sorted into a priority queue 2. sequentially remove them; they will come out in sorted order.\\n\\nName Priority Queue Implementation Best Average Worst [[Heapsort]] Heap $n \\\\log n$ $n \\\\log n$ $n \\\\log n$ Smoothsort Leonardo Heap $n$ $n \\\\log n$ $n \\\\log n$ Selection sort Unordered Array {.bad-cell}$n^2$ {.bad-cell}$n^2$ {.bad-cell}$n^2$ [[Insertion sort]] Ordered Array $n$ {.bad-cell}$n^2$ {.bad-cell}$n^2$ Tree sort Self-balancing binary search tree $n \\\\log n$ $n \\\\log n$ $n \\\\log n$\\n\\nA sorting algorithm can also be used to implement a priority queue. If we can sort up to $n$ keys in $S(n)$ time per key, then there is a priority queue supporting enqueue, dequeue, and delete in $O(S(n))$ time and peek in constant time. - For example, if one has an $O(n \\\\log n)$ sort algorithm, one can create a priority queue with $O(1)$ polling and $O(\\\\log n)$ insertion.\\n\\nApplications\\n\\nGenerally, priority queues share the same applications as heaps (see [[Heap#Applications]]).')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T17:39:15.699963Z",
     "start_time": "2025-08-06T17:39:13.117207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Indexing: Let's chunk and insert our documents into FAISS\n",
    "\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=64)\n",
    "documents = text_splitter.split_documents(full_documents)\n",
    "\n",
    "# store in FAISS with nomic embeddings (ollama)\n",
    "embedding_model = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "vectorstore = FAISS.from_documents(documents=documents, embedding=embedding_model)\n",
    "\n",
    "documents[0]"
   ],
   "id": "152b0523d18633b9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'rsc/vault/Priority Queue.md'}, page_content='A priority queue is an abstract data structure, similar to a queue, in which each element has an associated priority and elements with high priority are served before elements with low priority.\\n\\n![[priority_queue_overview.png|500]]\\n\\nPriority queues are commonly implemented using [[Heap|heaps]], giving $O(\\\\log n)$ performance for inserts and removals, and $O(n)$ to build the heap initially from a set of $n$ elements.\\n\\nOperations\\n\\nPriority queues support the following operations:')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T18:14:57.693417Z",
     "start_time": "2025-08-06T18:14:57.691693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a query\n",
    "\n",
    "# query = \"Given an integer array nums, handle multiple queries of the following types: 1. Update the value of an element in nums. 2. Calculate the sum of the elements of nums between indices left and right inclusive where left <= right. Give a broad strokes overview of how you'd solve this?\"\n",
    "\n",
    "# query = \"What data structures and algorithms do you use to solve the trapping rainwater coding problem?\"\n",
    "\n",
    "# query = \"What is a fenwick tree?\"\n",
    "\n",
    "# query = \"What is the seam carving algorithm?\"\n",
    "\n",
    "# query = \"What is a multiset good for?\"\n",
    "\n",
    "query = \"What is the relationship between a prefix sum and an integral image?\""
   ],
   "id": "d316ab6d819dbacd",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T18:14:59.494915Z",
     "start_time": "2025-08-06T18:14:57.700431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retrieval and generation: Let's set up a RAG chain\n",
    "\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template('''\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "''')\n",
    "\n",
    "llm = OllamaLLM(model=\"llama3.2:1b\")\n",
    "\n",
    "rag_chain = (\n",
    "        {\n",
    "            \"context\": vectorstore.as_retriever(),\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_response = rag_chain.invoke(query)\n",
    "print(rag_response)"
   ],
   "id": "84155e055c78f0ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A prefix sum typically represents a running sum of elements from an array up to a given index, whereas an integral image is the 2D extension of a prefix sum that can also represent sums in higher dimensions. The relationship between the two is analogous; the value for each pixel in an integral image corresponds to the sum of all pixels in the source image (or other dimension). This means that, conceptually, an integral image is a 2-dimensional analogue of a prefix sum.\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T18:14:59.995430Z",
     "start_time": "2025-08-06T18:14:59.515540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's set up a simple chain to test our RAG against\n",
    "\n",
    "simple_prompt = PromptTemplate.from_template('''\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "Question: {question}\n",
    "Answer:\n",
    "''')\n",
    "simple_chain = simple_prompt | llm | StrOutputParser()\n",
    "\n",
    "simple_response = simple_chain.invoke(query)\n",
    "print(simple_response)"
   ],
   "id": "cb4eea0754a2d4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A prefix sum is the result of adding all the digits in a number, while integral image represents a single digit. The process of converting a decimal to another base involves both these operations. For example, 128 in base 10 can be converted to integral image (one with the digit 1) in base 6 by prefix summing the original value.\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T18:15:03.789778Z",
     "start_time": "2025-08-06T18:15:00.007337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use a stronger LLM to judge which response is better\n",
    "\n",
    "judge_prompt = PromptTemplate.from_template('''\n",
    "You will be given a question and two different answers to that question. Based on your knowledge, judge which answer is better, in terms of factual accuracy and relevance to the question. If they are about the same, then say so. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Question: {question}\n",
    "Answer1: {answer1}\n",
    "Answer2: {answer2}\n",
    "\n",
    "Your response:\n",
    "''')\n",
    "judge_chain = (\n",
    "        judge_prompt\n",
    "        | OllamaLLM(model=\"gemma3n\")\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "judge_response = judge_chain.invoke({\n",
    "    \"question\": query,\n",
    "    \"answer1\": rag_response,\n",
    "    \"answer2\": simple_response,\n",
    "})\n",
    "print(judge_response)"
   ],
   "id": "ce8ef6c840144e13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer1 is significantly better. It accurately describes the relationship between a prefix sum and an integral image, highlighting the 2D analogy and how integral images store cumulative sums. Answer2 provides a fundamentally incorrect definition of both concepts and a nonsensical example, demonstrating a lack of understanding. \n",
      "\n"
     ]
    }
   ],
   "execution_count": 61
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
