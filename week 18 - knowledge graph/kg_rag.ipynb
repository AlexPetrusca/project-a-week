{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T01:51:39.521634Z",
     "start_time": "2025-08-07T01:51:39.519524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's perform KG-RAG on a mock Obsidian vault\n",
    "#   - By leveraging Graphiti, we're hoping to see improvements over traditional RAG!"
   ],
   "id": "e36d5e02083b80e9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-07T01:51:39.537279Z",
     "start_time": "2025-08-07T01:51:39.530279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import asyncio\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # load environment variables"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T01:51:39.613880Z",
     "start_time": "2025-08-07T01:51:39.611961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Init: Set up logging and environment variables for connecting to the Neo4j database\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from logging import INFO\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Neo4j connection parameters\n",
    "neo4j_uri = os.environ.get('NEO4J_URI', 'bolt://localhost:7687')\n",
    "neo4j_user = os.environ.get('NEO4J_USER', 'neo4j')\n",
    "neo4j_password = os.environ.get('NEO4J_PASSWORD', \"password\")\n",
    "\n",
    "if not neo4j_uri or not neo4j_user or not neo4j_password:\n",
    "    raise ValueError('NEO4J_URI, NEO4J_USER, and NEO4J_PASSWORD must be set')"
   ],
   "id": "1234eb39d86b0db8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T01:51:40.104113Z",
     "start_time": "2025-08-07T01:51:39.623086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Init: Configure Graphiti to work with Ollama\n",
    "\n",
    "from graphiti_core import Graphiti\n",
    "from graphiti_core.llm_client.config import LLMConfig\n",
    "from graphiti_core.llm_client.openai_client import OpenAIClient\n",
    "from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig\n",
    "from graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient\n",
    "\n",
    "llm_config = LLMConfig(\n",
    "    api_key=\"abc\",  # Ollama doesn't require a real API key\n",
    "    model=\"gemma3n\",\n",
    "    small_model=\"gemma3n\",\n",
    "    base_url=\"http://localhost:11434/v1\",  # Ollama provides this port\n",
    ")\n",
    "llm_client = OpenAIClient(config=llm_config)\n",
    "\n",
    "graphiti = Graphiti(\n",
    "    neo4j_uri,\n",
    "    neo4j_user,\n",
    "    neo4j_password,\n",
    "    llm_client=llm_client,\n",
    "    embedder=OpenAIEmbedder(\n",
    "        config=OpenAIEmbedderConfig(\n",
    "            api_key=\"abc\",\n",
    "            embedding_model=\"nomic-embed-text\",\n",
    "            embedding_dim=768,\n",
    "            base_url=\"http://localhost:11434/v1\",\n",
    "        )\n",
    "    ),\n",
    "    cross_encoder=OpenAIRerankerClient(client=llm_client, config=llm_config),\n",
    ")"
   ],
   "id": "189d71db7e6da086",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T01:51:40.201674Z",
     "start_time": "2025-08-07T01:51:40.110494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Init: Clear Neo4J and initialize Graphiti\n",
    "\n",
    "# Delete all nodes and edges in Neo4j\n",
    "await graphiti.driver.execute_query(\"MATCH (n) DETACH DELETE n\")\n",
    "\n",
    "# Initialize the graph database with graphiti's indices. This only needs to be done once.\n",
    "await graphiti.build_indices_and_constraints()"
   ],
   "id": "809c674683c92dd0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 18:51:40 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX entity_uuid IF NOT EXISTS FOR (e:Entity) ON (e.uuid)` has no effect.} {description: `RANGE INDEX entity_uuid FOR (e:Entity) ON (e.uuid)` already exists.} {position: None} for query: 'CREATE INDEX entity_uuid IF NOT EXISTS FOR (n:Entity) ON (n.uuid)'\n",
      "2025-08-06 18:51:40 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX episode_uuid IF NOT EXISTS FOR (e:Episodic) ON (e.uuid)` has no effect.} {description: `RANGE INDEX episode_uuid FOR (e:Episodic) ON (e.uuid)` already exists.} {position: None} for query: 'CREATE INDEX episode_uuid IF NOT EXISTS FOR (n:Episodic) ON (n.uuid)'\n",
      "2025-08-06 18:51:40 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX community_uuid IF NOT EXISTS FOR (e:Community) ON (e.uuid)` has no effect.} {description: `RANGE INDEX community_uuid FOR (e:Community) ON (e.uuid)` already exists.} {position: None} for query: 'CREATE INDEX community_uuid IF NOT EXISTS FOR (n:Community) ON (n.uuid)'\n",
      "2025-08-06 18:51:40 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX relation_uuid IF NOT EXISTS FOR ()-[e:RELATES_TO]-() ON (e.uuid)` has no effect.} {description: `RANGE INDEX relation_uuid FOR ()-[e:RELATES_TO]-() ON (e.uuid)` already exists.} {position: None} for query: 'CREATE INDEX relation_uuid IF NOT EXISTS FOR ()-[e:RELATES_TO]-() ON (e.uuid)'\n",
      "2025-08-06 18:51:40 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX mention_uuid IF NOT EXISTS FOR ()-[e:MENTIONS]-() ON (e.uuid)` has no effect.} {description: `RANGE INDEX mention_uuid FOR ()-[e:MENTIONS]-() ON (e.uuid)` already exists.} {position: None} for query: 'CREATE INDEX mention_uuid IF NOT EXISTS FOR ()-[e:MENTIONS]-() ON (e.uuid)'\n",
      "2025-08-06 18:51:40 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX has_member_uuid IF NOT EXISTS FOR ()-[e:HAS_MEMBER]-() ON (e.uuid)` has no effect.} {description: `RANGE INDEX has_member_uuid FOR ()-[e:HAS_MEMBER]-() ON (e.uuid)` already exists.} {position: None} for query: 'CREATE INDEX has_member_uuid IF NOT EXISTS FOR ()-[e:HAS_MEMBER]-() ON (e.uuid)'\n",
      "2025-08-06 18:51:40 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX entity_group_id IF NOT EXISTS FOR (e:Entity) ON (e.group_id)` has no effect.} {description: `RANGE INDEX entity_group_id FOR (e:Entity) ON (e.group_id)` already exists.} {position: None} for query: 'CREATE INDEX entity_group_id IF NOT EXISTS FOR (n:Entity) ON (n.group_id)'\n",
      "2025-08-06 18:51:40 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX episode_group_id IF NOT EXISTS FOR (e:Episodic) ON (e.group_id)` has no effect.} {description: `RANGE INDEX episode_group_id FOR (e:Episodic) ON (e.group_id)` already exists.} {position: None} for query: 'CREATE INDEX episode_group_id IF NOT EXISTS FOR (n:Episodic) ON (n.group_id)'\n",
      "2025-08-06 18:51:40 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX relation_group_id IF NOT EXISTS FOR ()-[e:RELATES_TO]-() ON (e.group_id)` has no effect.} {description: `RANGE INDEX relation_group_id FOR ()-[e:RELATES_TO]-() ON (e.group_id)` already exists.} {position: None} for query: 'CREATE INDEX relation_group_id IF NOT EXISTS FOR ()-[e:RELATES_TO]-() ON (e.group_id)'\n",
      "2025-08-06 18:51:40 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX mention_group_id IF NOT EXISTS FOR ()-[e:MENTIONS]-() ON (e.group_id)` has no effect.} {description: `RANGE INDEX mention_group_id FOR ()-[e:MENTIONS]-() ON (e.group_id)` already exists.} {position: None} for query: 'CREATE INDEX mention_group_id IF NOT EXISTS FOR ()-[e:MENTIONS]-() ON (e.group_id)'\n",
      "2025-08-06 18:51:40 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX name_entity_index IF NOT EXISTS FOR (e:Entity) ON (e.name)` has no effect.} {description: `RANGE INDEX name_entity_index FOR (e:Entity) ON (e.name)` already exists.} {position: None} for query: 'CREATE INDEX name_entity_index IF NOT EXISTS FOR (n:Entity) ON (n.name)'\n",
      "2025-08-06 18:51:40 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX created_at_entity_index IF NOT EXISTS FOR (e:Entity) ON (e.created_at)` has no effect.} {description: `RANGE INDEX created_at_entity_index FOR (e:Entity) ON (e.created_at)` already exists.} {position: None} for query: 'CREATE INDEX created_at_entity_index IF NOT EXISTS FOR (n:Entity) ON (n.created_at)'\n",
      "2025-08-06 18:51:40 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX created_at_episodic_index IF NOT EXISTS FOR (e:Episodic) ON (e.created_at)` has no effect.} {description: `RANGE INDEX created_at_episodic_index FOR (e:Episodic) ON (e.created_at)` already exists.} {position: None} for query: 'CREATE INDEX created_at_episodic_index IF NOT EXISTS FOR (n:Episodic) ON (n.created_at)'\n",
      "2025-08-06 18:51:40 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX valid_at_episodic_index IF NOT EXISTS FOR (e:Episodic) ON (e.valid_at)` has no effect.} {description: `RANGE INDEX valid_at_episodic_index FOR (e:Episodic) ON (e.valid_at)` already exists.} {position: None} for query: 'CREATE INDEX valid_at_episodic_index IF NOT EXISTS FOR (n:Episodic) ON (n.valid_at)'\n",
      "2025-08-06 18:51:40 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX name_edge_index IF NOT EXISTS FOR ()-[e:RELATES_TO]-() ON (e.name)` has no effect.} {description: `RANGE INDEX name_edge_index FOR ()-[e:RELATES_TO]-() ON (e.name)` already exists.} {position: None} for query: 'CREATE INDEX name_edge_index IF NOT EXISTS FOR ()-[e:RELATES_TO]-() ON (e.name)'\n",
      "2025-08-06 18:51:40 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX created_at_edge_index IF NOT EXISTS FOR ()-[e:RELATES_TO]-() ON (e.created_at)` has no effect.} {description: `RANGE INDEX created_at_edge_index FOR ()-[e:RELATES_TO]-() ON (e.created_at)` already exists.} {position: None} for query: 'CREATE INDEX created_at_edge_index IF NOT EXISTS FOR ()-[e:RELATES_TO]-() ON (e.created_at)'\n",
      "2025-08-06 18:51:40 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX expired_at_edge_index IF NOT EXISTS FOR ()-[e:RELATES_TO]-() ON (e.expired_at)` has no effect.} {description: `RANGE INDEX expired_at_edge_index FOR ()-[e:RELATES_TO]-() ON (e.expired_at)` already exists.} {position: None} for query: 'CREATE INDEX expired_at_edge_index IF NOT EXISTS FOR ()-[e:RELATES_TO]-() ON (e.expired_at)'\n",
      "2025-08-06 18:51:40 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX valid_at_edge_index IF NOT EXISTS FOR ()-[e:RELATES_TO]-() ON (e.valid_at)` has no effect.} {description: `RANGE INDEX valid_at_edge_index FOR ()-[e:RELATES_TO]-() ON (e.valid_at)` already exists.} {position: None} for query: 'CREATE INDEX valid_at_edge_index IF NOT EXISTS FOR ()-[e:RELATES_TO]-() ON (e.valid_at)'\n",
      "2025-08-06 18:51:40 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX invalid_at_edge_index IF NOT EXISTS FOR ()-[e:RELATES_TO]-() ON (e.invalid_at)` has no effect.} {description: `RANGE INDEX invalid_at_edge_index FOR ()-[e:RELATES_TO]-() ON (e.invalid_at)` already exists.} {position: None} for query: 'CREATE INDEX invalid_at_edge_index IF NOT EXISTS FOR ()-[e:RELATES_TO]-() ON (e.invalid_at)'\n",
      "2025-08-06 18:51:40 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE FULLTEXT INDEX episode_content IF NOT EXISTS FOR (e:Episodic) ON EACH [e.content, e.source, e.source_description, e.group_id]` has no effect.} {description: `FULLTEXT INDEX episode_content FOR (e:Episodic) ON EACH [e.content, e.source, e.source_description, e.group_id]` already exists.} {position: None} for query: 'CREATE FULLTEXT INDEX episode_content IF NOT EXISTS\\n        FOR (e:Episodic) ON EACH [e.content, e.source, e.source_description, e.group_id]'\n",
      "2025-08-06 18:51:40 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE FULLTEXT INDEX node_name_and_summary IF NOT EXISTS FOR (e:Entity) ON EACH [e.name, e.summary, e.group_id]` has no effect.} {description: `FULLTEXT INDEX node_name_and_summary FOR (e:Entity) ON EACH [e.name, e.summary, e.group_id]` already exists.} {position: None} for query: 'CREATE FULLTEXT INDEX node_name_and_summary IF NOT EXISTS\\n        FOR (n:Entity) ON EACH [n.name, n.summary, n.group_id]'\n",
      "2025-08-06 18:51:40 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE FULLTEXT INDEX community_name IF NOT EXISTS FOR (e:Community) ON EACH [e.name, e.group_id]` has no effect.} {description: `FULLTEXT INDEX community_name FOR (e:Community) ON EACH [e.name, e.group_id]` already exists.} {position: None} for query: 'CREATE FULLTEXT INDEX community_name IF NOT EXISTS\\n        FOR (n:Community) ON EACH [n.name, n.group_id]'\n",
      "2025-08-06 18:51:40 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE FULLTEXT INDEX edge_name_and_fact IF NOT EXISTS FOR ()-[e:RELATES_TO]-() ON EACH [e.name, e.fact, e.group_id]` has no effect.} {description: `FULLTEXT INDEX edge_name_and_fact FOR ()-[e:RELATES_TO]-() ON EACH [e.name, e.fact, e.group_id]` already exists.} {position: None} for query: 'CREATE FULLTEXT INDEX edge_name_and_fact IF NOT EXISTS\\n        FOR ()-[e:RELATES_TO]-() ON EACH [e.name, e.fact, e.group_id]'\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T01:51:44.243770Z",
     "start_time": "2025-08-07T01:51:40.208138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Indexing: Let's load our full documents\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(\"./\", glob=\"**/*.md\", show_progress=True, use_multithreading=True)\n",
    "\n",
    "full_documents = loader.load()\n",
    "full_documents[0]"
   ],
   "id": "ef72c59461e0dc74",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/66 [00:00<?, ?it/s]2025-08-06 18:51:43 - unstructured - WARNING - Need to load profiles.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - Need to load profiles.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - Need to load profiles.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - Need to load profiles.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"![[priority_queue_overview.png|500]]\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"![[integral_image_overview.png]]\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Operations\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Operation\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Multiply by two:\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"x <<= 1\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"![[integral_image_algorithm.jpg]]\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Divide by two:\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"![[integral_image_compute_sum.jpg]]\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"x >>= 1\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Applications\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Applications\". Defaulting to English.\n",
      "  2%|▏         | 1/66 [00:02<02:50,  2.62s/it]2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Swap two numbers:\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Complexity Analysis\". Defaulting to English.\n",
      "  6%|▌         | 4/66 [00:02<00:32,  1.91it/s]2025-08-06 18:51:43 - unstructured - WARNING - short text: \"![[algo_seam_carving_overview.png]]\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Structure\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"How It Works\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"![[union_find_structure.png|500]]\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Energy Map Creation\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Operation\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"![[union_find_operations.png]]\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Implementation\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Seam Identification\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Path Compression\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Seam Removal or Insertion\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Path Halving\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Pros / Cons\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"![[sorting_network_overview.png]]\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Applications\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Zero-One Principle\". Defaulting to English.\n",
      "  9%|▉         | 6/66 [00:02<00:21,  2.84it/s]2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Parallelism\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Complexity Analysis\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"![[cs_ds_multimap.png]]\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"![[sorting_network_insertion_sort.png|400]]\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Language Support\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"%% stub %%\". Defaulting to English.\n",
      " 14%|█▎        | 9/66 [00:03<00:11,  4.84it/s]2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Bitonic Mergesort\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Applications\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"![[sorting_network_bitonic_sort_directional.png]]\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"![[sorting_network_bitonic_sort.png]]\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"![[sorting_network_batcher_odd_even_mergesort.png|400]]\". Defaulting to English.\n",
      "2025-08-06 18:51:43 - unstructured - WARNING - short text: \"Applications\". Defaulting to English.\n",
      " 32%|███▏      | 21/66 [00:03<00:02, 20.35it/s]2025-08-06 18:51:44 - unstructured - WARNING - short text: \"%%\". Defaulting to English.\n",
      "2025-08-06 18:51:44 - unstructured - WARNING - short text: \"stub # todo\". Defaulting to English.\n",
      "2025-08-06 18:51:44 - unstructured - WARNING - short text: \"%%\". Defaulting to English.\n",
      "2025-08-06 18:51:44 - unstructured - WARNING - short text: \"%% stub %%\". Defaulting to English.\n",
      "2025-08-06 18:51:44 - unstructured - WARNING - short text: \"%% stub %%\". Defaulting to English.\n",
      " 41%|████      | 27/66 [00:03<00:05,  7.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'rsc/vault/Priority Queue.md'}, page_content='A priority queue is an abstract data structure, similar to a queue, in which each element has an associated priority and elements with high priority are served before elements with low priority.\\n\\n![[priority_queue_overview.png|500]]\\n\\nPriority queues are commonly implemented using [[Heap|heaps]], giving $O(\\\\log n)$ performance for inserts and removals, and $O(n)$ to build the heap initially from a set of $n$ elements.\\n\\nOperations\\n\\nPriority queues support the following operations:\\n\\nBasic - enqueue: add an element to the queue with an associated priority. - dequeue: remove the highest priority element from the queue, and return it. - delete: remove an element from the queue. - peek: return the highest priority element from the queue.\\n\\nInspection - size: return the number of elements in the queue. - is_empty: check whether the queue has no elements.\\n\\nEquivalence of priority queues and sorting algorithms\\n\\nThe semantics of priority queues naturally suggest a sorting method: 1. insert all the elements to be sorted into a priority queue 2. sequentially remove them; they will come out in sorted order.\\n\\nName Priority Queue Implementation Best Average Worst [[Heapsort]] Heap $n \\\\log n$ $n \\\\log n$ $n \\\\log n$ Smoothsort Leonardo Heap $n$ $n \\\\log n$ $n \\\\log n$ Selection sort Unordered Array {.bad-cell}$n^2$ {.bad-cell}$n^2$ {.bad-cell}$n^2$ [[Insertion sort]] Ordered Array $n$ {.bad-cell}$n^2$ {.bad-cell}$n^2$ Tree sort Self-balancing binary search tree $n \\\\log n$ $n \\\\log n$ $n \\\\log n$\\n\\nA sorting algorithm can also be used to implement a priority queue. If we can sort up to $n$ keys in $S(n)$ time per key, then there is a priority queue supporting enqueue, dequeue, and delete in $O(S(n))$ time and peek in constant time. - For example, if one has an $O(n \\\\log n)$ sort algorithm, one can create a priority queue with $O(1)$ polling and $O(\\\\log n)$ insertion.\\n\\nApplications\\n\\nGenerally, priority queues share the same applications as heaps (see [[Heap#Applications]]).')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T02:35:41.119303Z",
     "start_time": "2025-08-07T01:51:44.250962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Indexing: Ingest chunked documents as episodes into Graphiti\n",
    "#   - Sooooooooooo slooooooooooow... and it breaks with Ollama models, because they're too weak\n",
    "#   - So you've got to have a ChatGPT subscription and pay a million dollars to build a knowledge graph\n",
    "\n",
    "from graphiti_core.nodes import EpisodeType\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "documents = text_splitter.split_documents(full_documents)\n",
    "\n",
    "for i in range(5):\n",
    "    doc = documents[i]\n",
    "    print(f'Adding episode... Obsidian chunk {i} ({i + 1}/{len(documents)})')\n",
    "    await graphiti.add_episode(\n",
    "        name=f'Obsidian chunk {i}',\n",
    "        episode_body=doc.page_content,\n",
    "        source=EpisodeType.text,\n",
    "        source_description=f\"Obsidian: {doc.metadata['source']}\",\n",
    "        reference_time=datetime.now(timezone.utc),\n",
    "    )"
   ],
   "id": "62859d03f9450ff4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding episode... Obsidian chunk 0 (1/305)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 18:51:46 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:51:46 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:51:51 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:51:58 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:51:58 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:51:58 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:52:01 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:52:01 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:52:01 - graphiti_core.graphiti - INFO - Completed add_episode in 17237.69783973694 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding episode... Obsidian chunk 1 (2/305)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 18:52:06 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:52:06 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:52:06 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:52:06 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:52:06 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:52:06 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:52:22 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:52:41 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:52:41 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:52:43 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:52:45 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:52:47 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:52:47 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:52:52 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:52:56 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:52:59 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:53:01 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:53:04 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:53:04 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:53:04 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:53:04 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:53:04 - graphiti_core.graphiti - INFO - Completed add_episode in 62818.57085227966 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding episode... Obsidian chunk 2 (3/305)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 18:53:10 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:53:10 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:53:10 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:53:10 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:53:10 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:53:10 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:53:10 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:53:10 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:53:10 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:53:10 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:53:42 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:54:10 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:54:11 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:54:14 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:54:17 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:54:20 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:54:22 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:54:25 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:54:28 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:54:31 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:54:31 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:54:36 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:02 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:10 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:16 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:22 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:28 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:34 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:41 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:47 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:47 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:47 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:47 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:47 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:47 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:47 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:47 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:47 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:47 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:47 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:47 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:47 - graphiti_core.graphiti - INFO - Completed add_episode in 163381.40487670898 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding episode... Obsidian chunk 3 (4/305)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 18:55:52 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:52 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:52 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:52 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:52 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:53 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:55:53 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:56:08 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:56:32 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:56:32 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:56:36 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:56:38 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:56:41 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:56:44 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:56:46 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:56:46 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:56:52 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:56:57 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:57:04 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:57:09 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:57:15 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:57:21 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:57:21 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:57:21 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:57:21 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:57:21 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:57:21 - graphiti_core.graphiti - INFO - Completed add_episode in 93732.83314704895 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding episode... Obsidian chunk 4 (5/305)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 18:57:26 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:57:26 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:57:26 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:57:26 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:57:26 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:57:26 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:57:26 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:57:43 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:57:51 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:57:51 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:57:54 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:57:54 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:00 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:07 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:14 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:23 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:30 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:37 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:37 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:37 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:37 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:37 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:37 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:38 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:38 - graphiti_core.graphiti - INFO - Completed add_episode in 76642.61603355408 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding episode... Obsidian chunk 5 (6/305)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 18:58:50 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:50 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:50 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:50 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:50 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:50 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:50 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:50 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:50 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:50 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:50 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:50 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:50 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:50 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:50 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:58:50 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 18:59:54 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:00:33 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:00:33 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:00:37 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:00:40 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:00:44 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:00:48 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:00:50 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:00:53 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:00:56 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:00:56 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:01:04 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:01:13 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:04:54 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:04:54 - graphiti_core.llm_client.openai_base_client - WARNING - Retrying after application error (attempt 1/2): Output length exceeded max tokens 8192: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=8192, prompt_tokens=815, total_tokens=9007, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2025-08-06 19:05:14 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:05:34 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:05:53 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:06:01 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:09:38 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:09:38 - graphiti_core.llm_client.openai_base_client - WARNING - Retrying after application error (attempt 1/2): Output length exceeded max tokens 8192: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=8192, prompt_tokens=814, total_tokens=9006, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2025-08-06 19:09:59 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:10:19 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:10:41 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:03 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:11 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:19 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:25 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:30 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:35 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:36 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:36 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:36 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:36 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:36 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:36 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:36 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:36 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:36 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:36 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:36 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:37 - graphiti_core.graphiti - INFO - Completed add_episode in 778958.2421779633 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding episode... Obsidian chunk 6 (7/305)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 19:11:43 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:43 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:43 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:43 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:43 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:43 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:11:43 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:12:20 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:13:07 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:13:07 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:13:11 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:13:15 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:13:18 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:13:23 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:13:26 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:13:30 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:13:33 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:13:38 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:13:41 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:13:45 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:13:48 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:13:52 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:13:55 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:14:00 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:14:00 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:14:00 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:18:20 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:18:20 - graphiti_core.llm_client.openai_base_client - WARNING - Retrying after application error (attempt 1/2): Output length exceeded max tokens 8192: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=8192, prompt_tokens=897, total_tokens=9089, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2025-08-06 19:18:41 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:23:04 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:23:04 - graphiti_core.llm_client.openai_base_client - WARNING - Retrying after application error (attempt 1/2): Output length exceeded max tokens 8192: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=8192, prompt_tokens=992, total_tokens=9184, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2025-08-06 19:23:19 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:23:33 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:23:43 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:23:56 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:28:20 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:28:20 - graphiti_core.llm_client.openai_base_client - WARNING - Retrying after application error (attempt 1/2): Output length exceeded max tokens 8192: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=8192, prompt_tokens=992, total_tokens=9184, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2025-08-06 19:28:32 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:28:33 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:28:33 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:28:33 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:28:33 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:28:33 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:28:33 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:28:33 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:28:33 - graphiti_core.graphiti - INFO - Completed add_episode in 1016551.7432689667 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding episode... Obsidian chunk 7 (8/305)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 19:28:43 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:28:43 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:28:43 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:28:43 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:28:43 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:28:43 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:28:43 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:28:43 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:28:43 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:28:43 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:29:16 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:29:49 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:29:49 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:29:55 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:30:01 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:30:07 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:30:12 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:30:17 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:30:22 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:30:22 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:30:36 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:30:51 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:31:06 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:31:18 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:31:32 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:31:56 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:32:07 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:32:20 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:32:33 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:32:34 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:32:34 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:32:34 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:32:34 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:32:34 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:32:34 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:32:34 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:32:34 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:32:34 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:32:34 - graphiti_core.graphiti - INFO - Completed add_episode in 240931.79392814636 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding episode... Obsidian chunk 8 (9/305)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 19:32:39 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:32:39 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:32:39 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:32:39 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:32:39 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:33:10 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:33:21 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:33:21 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:33:27 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:33:27 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:33:40 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:33:54 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:34:07 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:34:21 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:34:21 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:34:21 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:34:21 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:34:21 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:34:21 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:34:21 - graphiti_core.graphiti - INFO - Completed add_episode in 106922.11818695068 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding episode... Obsidian chunk 9 (10/305)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 19:34:25 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:34:25 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:34:25 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:34:25 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:34:43 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:34:53 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:34:54 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:34:57 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:34:57 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:35:05 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:35:28 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:35:40 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:35:40 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:35:41 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:35:41 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 19:35:41 - graphiti_core.graphiti - INFO - Completed add_episode in 79671.33021354675 ms\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T03:15:41.540334Z",
     "start_time": "2025-08-07T03:15:41.206692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retrieval and generation: Let's set up a RAG chain (with whatever we've got)\n",
    "\n",
    "from pydantic import Field\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "class CustomGraphitiRetriever(BaseRetriever):\n",
    "    graphiti: Graphiti = Field(...)  # required field\n",
    "    k: int = 5  # optionally limit results\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True  # required for non-Pydantic types\n",
    "\n",
    "    def _get_relevant_documents(self, query, *, run_manager):\n",
    "        print(f'Getting relevant documents... query={query}')\n",
    "        raise NotImplementedError(\"This retriever only supports async\")\n",
    "\n",
    "    async def _aget_relevant_documents(self, query, *, run_manager):\n",
    "        results = await graphiti.search(query)\n",
    "        for res in results:\n",
    "            print(res.fact)\n",
    "        return [Document(page_content=node.fact) for node in results]\n",
    "\n",
    "prompt = PromptTemplate.from_template('''\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. A longer answer isn't necessarily better. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "''')\n",
    "\n",
    "llm = OllamaLLM(model=\"llama3.2:1b\")\n",
    "\n",
    "rag_chain = (\n",
    "        {\n",
    "            \"context\": CustomGraphitiRetriever(graphiti=graphiti),\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "query = \"What is the relationship between a prefix sum and an integral image?\"\n",
    "async def call_chain():\n",
    "    return await rag_chain.ainvoke(query)\n",
    "\n",
    "rag_response = await call_chain()\n",
    "print(rag_response)"
   ],
   "id": "cd636853583b1e73",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 20:15:41 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-06 20:15:41 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heapsort $n \\log n$\n",
      "Heapsort $n \\log n$\n",
      "Generally, priority queues share the same applications as heaps\n",
      "Self-balancing binary search tree $n \\log n$\n",
      "Equivalence of priority queues and sorting algorithms\n",
      "n is a number\n",
      "Insertion sort $n$\n",
      "Insertion sort $n$\n",
      "Basic - enqueue: add an element to the queue with an associated priority.\n",
      "is_empty: check whether the queue has no elements.\n",
      "I don't know what the relationship between a prefix sum and an integral image is in this context.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# whelp... 10 chunks in 45 minutes... that's prohibitive... Looks like I'm not going to be using Graphiti for QuizBot\n",
    "#   - Still, it was interesting to explore and seems promising:\n",
    "#       - Building knowledge graphs from unstructured data using LLMs has potential.\n",
    "#       - Hooking up agents to KGs like Graphiti via MCP to give them a sort of \"long-term memory\" is an interesting research direction.\n",
    "#   - I can still use a simple knowledge graph, like Neo4j by itself, to store my raw documents for multi-index retrieval\n",
    "#       - The structure of an Obsidian vault naturally lends itself to being stored in a knowledge graph\n",
    "#           - (In fact, that's the whole selling point of Obsidian)\n",
    "#       - So I'm thinking a good process might be:\n",
    "#           1. I'll do similarity searches against a vector database (FAISS)\n",
    "#           2. I'll include a multi-index id in the chunk documents I retrieve\n",
    "#           3. I can then use that id to look up the parent document in the knowledge graph (Neo4J)\n",
    "#           4. From there, I can do knowledge graph shenanigans (center node search, etc.) to retrieve related documents"
   ],
   "id": "f5a8e4afa56173c8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
