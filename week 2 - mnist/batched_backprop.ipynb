{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T00:25:56.607053Z",
     "start_time": "2025-02-25T00:25:56.603588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from src.datagen import DatasetGenerator"
   ],
   "id": "8439de0eac0b66da",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T00:25:56.651905Z",
     "start_time": "2025-02-25T00:25:56.646424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define activation function\n",
    "def sigma(z):\n",
    "    return 1 / (1 + np.e**(-z)) # sigmoid\n",
    "\n",
    "def sigma_prime(z):\n",
    "    y = sigma(z)\n",
    "    return y * (1 - y)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T00:25:56.776355Z",
     "start_time": "2025-02-25T00:25:56.765652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define loss function\n",
    "def loss(y_true, y_pred):\n",
    "    return (y_true - y_pred)**2 / 2 # squared error loss\n",
    "\n",
    "def loss_prime(y_true, y_pred):\n",
    "    return -(y_true - y_pred) # squared error loss"
   ],
   "id": "fd13186d1e006e7e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T00:25:56.992334Z",
     "start_time": "2025-02-25T00:25:56.987433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define training routine\n",
    "def train(training_set, batch_size=32, epochs=10, eta=0.01, validation_set=None):\n",
    "    for sample in training_set:\n",
    "        # read sample\n",
    "        x = sample['data']\n",
    "        y_true = sample['label']\n",
    "\n",
    "        # feed forward\n",
    "        z = [np.empty(0)]\n",
    "        a = [x]\n",
    "        for i, (w, b) in enumerate(zip(weights, biases)):\n",
    "            z.append(w @ a[i] + b)  # weighted sum\n",
    "            a.append(sigma(z[i + 1]))  # activation\n",
    "\n",
    "        # backpropagate\n",
    "        gradient_i = loss_prime(y_true, a[-1])\n",
    "        for i in range(1, len(weights) + 1):\n",
    "            if i == 1:\n",
    "                w_i = np.identity(gradient_i.shape[0])\n",
    "            else:\n",
    "                w_i = weights[-i + 1].T\n",
    "\n",
    "            gradient_i = (w_i @ gradient_i) * sigma_prime(z[-i])\n",
    "            weight_gradient_i = gradient_i @ a[-i - 1].T\n",
    "            weights[-i] -= eta * weight_gradient_i\n",
    "            biases[-i] -= eta * gradient_i"
   ],
   "id": "8e3589a5c78056ef",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T00:25:57.029024Z",
     "start_time": "2025-02-25T00:25:57.009429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define validation routine\n",
    "def feed_forward(x):\n",
    "    for w, b in zip(weights, biases):\n",
    "        z = w @ x + b  # weighted sum\n",
    "        y = sigma(z)  # activation\n",
    "        x = y  # output of this layer is input of the next\n",
    "    return x\n",
    "\n",
    "def validate(validation_set, verbose=False, print_samples=10):\n",
    "    average_loss = 0\n",
    "    accuracy = 0\n",
    "    num_samples = 0\n",
    "    for sample in validation_set:\n",
    "        x = sample['data']\n",
    "        y_pred = feed_forward(x)\n",
    "        y_true = sample['label']\n",
    "\n",
    "        sample_loss = loss(y_true, y_pred)\n",
    "\n",
    "        num_samples += 1\n",
    "        average_loss += sample_loss\n",
    "        if np.array_equal(np.round(y_pred), y_true):\n",
    "            accuracy += 1\n",
    "\n",
    "    accuracy /= num_samples\n",
    "    average_loss /= num_samples\n",
    "    print(f\"Accuracy: {accuracy:<10} Average Loss: {average_loss}\")"
   ],
   "id": "96037e8b5e1f9513",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T00:26:01.163995Z",
     "start_time": "2025-02-25T00:25:57.075502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create training set and test set\n",
    "datagen = DatasetGenerator(lambda x, y: int(x * math.sin(x) - y * math.cos(y) > 0))\n",
    "training_set = list(datagen.generate_samples(1000000))\n",
    "test_set = list(datagen.generate_samples(10000))"
   ],
   "id": "4be4a2c187a67558",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T00:26:01.186119Z",
     "start_time": "2025-02-25T00:26:01.180762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define network\n",
    "dims = [2, 4, 1]\n",
    "weights = []\n",
    "biases = []\n",
    "for i in range(len(dims) - 1):\n",
    "    num_neurons = dims[i + 1]\n",
    "    num_weights = dims[i]\n",
    "    weights.append(np.random.randn(num_neurons, num_weights))\n",
    "    biases.append(np.random.randn(num_neurons, 1))\n",
    "\n",
    "for w, b in zip(weights, biases):\n",
    "    print(w)\n",
    "    print(b)\n",
    "    print()"
   ],
   "id": "ab7b0748aab75d5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.12577488 -0.04156878]\n",
      " [ 0.91719596 -1.66969848]\n",
      " [-1.32438206 -1.36592078]\n",
      " [-0.85760964  1.69802471]]\n",
      "[[-0.69954978]\n",
      " [-2.46421343]\n",
      " [-1.58590568]\n",
      " [-0.22694209]]\n",
      "\n",
      "[[-0.22736597  0.85507586  0.21094454  0.7561336 ]]\n",
      "[[-1.1741493]]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T00:26:01.414863Z",
     "start_time": "2025-02-25T00:26:01.243535Z"
    }
   },
   "cell_type": "code",
   "source": "validate(test_set)",
   "id": "e3ce6d9491f9be3a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2346     Average Loss: [[0.18624124]]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T00:26:01.505503Z",
     "start_time": "2025-02-25T00:26:01.502122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create batch of samples\n",
    "batch_size = 32\n",
    "x = training_set[0]['data']\n",
    "y_true = training_set[0]['label']\n",
    "for i in range(1, batch_size):\n",
    "    x = np.hstack((x, training_set[i]['data']))\n",
    "    y_true = np.hstack((y_true, training_set[i]['label']))\n",
    "\n",
    "print(x)\n",
    "print(y_true)"
   ],
   "id": "e01c407afcf78dc3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.85469287  1.43014563 -1.49381389 -0.93101493 -1.24957728 -1.04611971\n",
      "   0.54875488 -0.02878888  1.3839304  -1.25173817  0.35877349  0.64832337\n",
      "   0.59558908 -0.22474586  1.67492692  1.77137423 -2.13930779  0.9324683\n",
      "  -0.12733466 -0.3935203   0.34739072 -0.38538803 -0.35621034  0.85913237\n",
      "  -0.84827385  0.02156693  0.3709242   1.76775351 -0.70045741 -0.08714703\n",
      "   1.36227411 -0.2177514 ]\n",
      " [-0.46254121  0.2085342   0.60672189 -0.3978825  -1.20655805  0.28911544\n",
      "  -0.01976887  1.12009763  1.12707697 -0.51588889 -1.24559596 -0.85919072\n",
      "   0.95353583 -0.99766473 -1.4451743   0.48023685  0.71216777  0.03959554\n",
      "  -0.49976874  0.28581001  0.44038408  2.32082627 -0.13466385  0.01951393\n",
      "   0.63961669  0.01509406 -0.20182126 -0.52377775  0.31442292 -0.17869961\n",
      "   0.76729056  0.68287616]]\n",
      "[[1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0]]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T00:26:01.694064Z",
     "start_time": "2025-02-25T00:26:01.689977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# feed forward sample\n",
    "z = [None]\n",
    "a = [x]\n",
    "for i, (w, b) in enumerate(zip(weights, biases)):\n",
    "    z.append(w @ a[i] + b)  # weighted sum\n",
    "    a.append(sigma(z[i + 1]))  # activation\n",
    "\n",
    "for z_i, a_i in zip(z, a):\n",
    "    print(z_i)\n",
    "    print(a_i)\n",
    "    print()"
   ],
   "id": "368e1b919f4d021f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[[ 0.85469287  1.43014563 -1.49381389 -0.93101493 -1.24957728 -1.04611971\n",
      "   0.54875488 -0.02878888  1.3839304  -1.25173817  0.35877349  0.64832337\n",
      "   0.59558908 -0.22474586  1.67492692  1.77137423 -2.13930779  0.9324683\n",
      "  -0.12733466 -0.3935203   0.34739072 -0.38538803 -0.35621034  0.85913237\n",
      "  -0.84827385  0.02156693  0.3709242   1.76775351 -0.70045741 -0.08714703\n",
      "   1.36227411 -0.2177514 ]\n",
      " [-0.46254121  0.2085342   0.60672189 -0.3978825  -1.20655805  0.28911544\n",
      "  -0.01976887  1.12009763  1.12707697 -0.51588889 -1.24559596 -0.85919072\n",
      "   0.95353583 -0.99766473 -1.4451743   0.48023685  0.71216777  0.03959554\n",
      "  -0.49976874  0.28581001  0.44038408  2.32082627 -0.13466385  0.01951393\n",
      "   0.63961669  0.01509406 -0.20182126 -0.52377775  0.31442292 -0.17869961\n",
      "   0.76729056  0.68287616]]\n",
      "\n",
      "[[-0.78782139 -0.88809468 -0.5368862  -0.56591199 -0.49222919 -0.57999237\n",
      "  -0.76774759 -0.74248995 -0.92046467 -0.52066768 -0.69289656 -0.74537706\n",
      "  -0.81409724 -0.62981068 -0.85013937 -0.94230702 -0.46008254 -0.8184768\n",
      "  -0.6627595  -0.66193558 -0.76154903 -0.74755157 -0.64914965 -0.80841822\n",
      "  -0.61944632 -0.70288979 -0.73781326 -0.90011596 -0.62452001 -0.68116054\n",
      "  -0.90278497 -0.70054845]\n",
      " [-0.90798823 -1.50067887 -4.8473761  -2.65379275 -1.59573252 -3.90644582\n",
      "  -1.92788962 -4.36084378 -3.07675677 -2.75092372 -0.05537815 -0.43498443\n",
      "  -3.51005887 -1.00455014  1.48502809 -1.64136689 -5.61548333 -1.67506989\n",
      "  -1.74654117 -3.30236519 -2.88089669 -6.69276987 -2.56608009 -1.70880308\n",
      "  -4.31021379 -2.46963485 -1.78702261  0.03171386 -3.63166161 -2.24576987\n",
      "  -2.495885   -3.80413142]\n",
      " [-2.08605094 -3.7648061  -0.43625939  0.19058977  1.71707477 -0.59535229\n",
      "  -2.28566409 -3.07774283 -4.95825613  0.77653726 -0.35967345 -1.27094707\n",
      "  -3.67714758  0.07447468 -1.83015525 -4.58784743  0.27459043 -2.87493435\n",
      "  -0.73462143 -1.45512828 -2.64751348 -4.24556952 -0.93020694 -2.75037967\n",
      "  -1.33613274 -1.63508582 -1.80147919 -3.2116478  -1.08770924 -1.2264002\n",
      "  -4.43813519 -2.23027437]\n",
      " [-1.74534134 -1.09935256  2.08439586 -0.10410904 -1.20405794  1.16114543\n",
      "  -0.7311276   1.69970098  0.4999904  -0.02943146 -2.64968242 -2.24187753\n",
      "   0.88140238 -1.72825724 -4.11731723 -0.93063567  2.81702737 -0.95940169\n",
      "  -0.96635832  0.59585716  0.22291532  4.04439075 -0.15011521 -0.93060716\n",
      "   1.58663068 -0.21980802 -0.88774775 -2.63237211  0.90767482 -0.4556403\n",
      "  -0.09236318  1.1193442 ]]\n",
      "[[0.31263665 0.29150317 0.36891223 0.36218065 0.37936857 0.35893435\n",
      "  0.31696655 0.3224599  0.28486322 0.37269612 0.33338903 0.32182945\n",
      "  0.30701809 0.34755347 0.29940362 0.28043457 0.38696624 0.30608709\n",
      "  0.34012    0.34030494 0.31831005 0.32135504 0.34318119 0.30822767\n",
      "  0.34990739 0.33117183 0.32348251 0.28902667 0.34875415 0.33600233\n",
      "  0.28847852 0.33169064]\n",
      " [0.28741168 0.18232429 0.00778782 0.06575563 0.1685789  0.01971534\n",
      "  0.12698435 0.01260665 0.04407626 0.0600345  0.486159   0.39293673\n",
      "  0.02902738 0.26804775 0.81533084 0.16227916 0.00362784 0.1577494\n",
      "  0.14848399 0.03549014 0.05310603 0.00123831 0.07135361 0.15331903\n",
      "  0.01325269 0.0780145  0.14343815 0.5079278  0.02578946 0.09571497\n",
      "  0.07614716 0.02179302]\n",
      " [0.11046001 0.02264732 0.39263264 0.54750373 0.84775166 0.35540774\n",
      "  0.09231724 0.04403473 0.00697616 0.68493334 0.41103862 0.21909517\n",
      "  0.02467097 0.51861007 0.13821978 0.01007225 0.5682195  0.05340665\n",
      "  0.32418141 0.18921357 0.06614243 0.01412519 0.28288273 0.06006521\n",
      "  0.20814675 0.16313485 0.1416711  0.03872974 0.25204989 0.2268121\n",
      "  0.01167992 0.09706459]\n",
      " [0.14863576 0.24986123 0.88937726 0.47399622 0.23075412 0.76154078\n",
      "  0.32494733 0.84549568 0.62245707 0.49264267 0.06600859 0.0960524\n",
      "  0.70711274 0.15081063 0.0160271  0.28279577 0.94358905 0.276998\n",
      "  0.27560696 0.64470792 0.5554992  0.9827813  0.46254151 0.28280155\n",
      "  0.83014154 0.44526818 0.29157483 0.06708384 0.71252412 0.38802057\n",
      "  0.47692561 0.75386705]]\n",
      "\n",
      "[[-0.86378402 -0.89082031 -0.49605648 -0.72637342 -0.76294754 -0.58810276\n",
      "  -0.87245805 -0.58808949 -0.72909667 -0.69056705 -0.69763014 -0.79248629\n",
      "  -0.67925825 -0.80053903 -0.50377844 -0.88319353 -0.425688   -0.88814205\n",
      "  -0.84773597 -0.69377742 -0.7671285  -0.50006206 -0.78174853 -0.88662421\n",
      "  -0.57076896 -0.81164356 -0.87469345 -0.74665316 -0.63946021 -0.82746108\n",
      "  -0.81154461 -0.64043033]]\n",
      "[[0.29654936 0.29094057 0.37846786 0.32599106 0.31800667 0.35707029\n",
      "  0.29474309 0.35707333 0.32539299 0.33390694 0.33233787 0.31163507\n",
      "  0.33642687 0.30991023 0.37665313 0.29251644 0.39515647 0.29149339\n",
      "  0.29990801 0.33319329 0.3171006  0.37752608 0.31394316 0.29180696\n",
      "  0.36105941 0.30754037 0.29427863 0.321551   0.34536857 0.30418218\n",
      "  0.30756145 0.34514927]]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T00:26:01.831893Z",
     "start_time": "2025-02-25T00:26:01.786906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# backpropagate sample\n",
    "eta = 1\n",
    "\n",
    "delta_weights = []\n",
    "delta_biases = []\n",
    "\n",
    "gradient_i = loss_prime(y_true, a[-1])\n",
    "for i in range(1, len(weights) + 1):\n",
    "    if i == 1:\n",
    "        w_i = np.identity(gradient_i.shape[0])\n",
    "    else:\n",
    "        w_i = weights[-i + 1].T\n",
    "\n",
    "    gradient_i = (w_i @ gradient_i) * sigma_prime(z[-i])\n",
    "    weight_gradient_i = gradient_i @ a[-i - 1].T\n",
    "    bias_gradient_i = gradient_i @ np.ones((batch_size, 1))\n",
    "\n",
    "    print(f\"weights {i}:\\t\\t {w_i.shape}\")\n",
    "    print(f\"sigma_prime {i}:\\t {sigma_prime(z[-i]).shape}\")\n",
    "    print(f\"gradient {i}:\\t\\t {gradient_i.shape}\")\n",
    "    print(f\"activation {i - 1}:\\t {a[-i - 1].T.shape}\")\n",
    "    print()\n",
    "\n",
    "    delta_weights.append(eta * weight_gradient_i)\n",
    "    delta_biases.append(eta * bias_gradient_i)\n",
    "\n",
    "for dw, db in zip(delta_weights, delta_biases):\n",
    "    print(dw)\n",
    "    print(db)\n",
    "    print()"
   ],
   "id": "5e0a88b53d120db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights 1:\t\t (1, 1)\n",
      "sigma_prime 1:\t (1, 32)\n",
      "gradient 1:\t\t (1, 32)\n",
      "activation 0:\t (32, 4)\n",
      "\n",
      "weights 2:\t\t (4, 1)\n",
      "sigma_prime 2:\t (4, 32)\n",
      "gradient 2:\t\t (4, 32)\n",
      "activation 1:\t (32, 2)\n",
      "\n",
      "[[-1.11698688 -0.64389237 -0.92099268 -1.29053779]]\n",
      "[[-3.38154356]]\n",
      "\n",
      "[[ 0.01252563 -0.0233166 ]\n",
      " [-0.19989891  0.16402863]\n",
      " [ 0.04334562  0.03092111]\n",
      " [-0.053431    0.04966222]]\n",
      "[[ 0.16927823]\n",
      " [-0.3381324 ]\n",
      " [-0.10252591]\n",
      " [-0.40378182]]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
