{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T21:57:56.745729Z",
     "start_time": "2025-02-06T21:57:56.596988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import numpy as np"
   ],
   "id": "8439de0eac0b66da",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T21:57:56.750964Z",
     "start_time": "2025-02-06T21:57:56.749196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define activation function\n",
    "def sigma(z):\n",
    "    return 1 / (1 + np.e**(-z)) # sigmoid\n",
    "\n",
    "def sigma_prime(z):\n",
    "    y = sigma(z)\n",
    "    return y * (1 - y)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T21:57:56.818751Z",
     "start_time": "2025-02-06T21:57:56.817204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define loss function\n",
    "def loss(y_true, y_pred):\n",
    "    return (y_true - y_pred)**2 / 2 # squared error loss\n",
    "\n",
    "def loss_prime(y_true, y_pred):\n",
    "    return -(y_true - y_pred) # squared error loss"
   ],
   "id": "fd13186d1e006e7e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T21:57:56.824148Z",
     "start_time": "2025-02-06T21:57:56.821949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define training routine\n",
    "def train(training_set, batch_size=32, epochs=10, eta=0.01, validation_set=None):\n",
    "    for sample in training_set:\n",
    "        # read sample\n",
    "        x = sample['data']\n",
    "        y_true = sample['label']\n",
    "\n",
    "        # feed forward\n",
    "        z = [np.empty(0)]\n",
    "        a = [x]\n",
    "        for i, (w, b) in enumerate(zip(weights, biases)):\n",
    "            z.append(w @ a[i] + b)  # weighted sum\n",
    "            a.append(sigma(z[i + 1]))  # activation\n",
    "\n",
    "        # backpropagate\n",
    "        gradient_i = loss_prime(y_true, a[-1])\n",
    "        for i in range(1, len(weights) + 1):\n",
    "            if i == 1:\n",
    "                w_i = np.identity(gradient_i.shape[0])\n",
    "            else:\n",
    "                w_i = weights[-i + 1].T\n",
    "\n",
    "            gradient_i = (w_i @ gradient_i) * sigma_prime(z[-i])\n",
    "            weight_gradient_i = gradient_i @ a[-i - 1].T\n",
    "            weights[-i] -= eta * weight_gradient_i\n",
    "            biases[-i] -= eta * gradient_i"
   ],
   "id": "8e3589a5c78056ef",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T21:57:56.829355Z",
     "start_time": "2025-02-06T21:57:56.827228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define validation routine\n",
    "def feed_forward(x):\n",
    "    for w, b in zip(weights, biases):\n",
    "        z = w @ x + b  # weighted sum\n",
    "        y = sigma(z)  # activation\n",
    "        x = y  # output of this layer is input of the next\n",
    "    return x\n",
    "\n",
    "def validate(validation_set, verbose=False, print_samples=10):\n",
    "    average_loss = 0\n",
    "    accuracy = 0\n",
    "    num_samples = 0\n",
    "    for sample in validation_set:\n",
    "        x = sample['data']\n",
    "        y_pred = feed_forward(x)\n",
    "        y_true = sample['label']\n",
    "\n",
    "        sample_loss = loss(y_true, y_pred)\n",
    "\n",
    "        num_samples += 1\n",
    "        average_loss += sample_loss\n",
    "        if np.array_equal(np.round(y_pred), y_true):\n",
    "            accuracy += 1\n",
    "\n",
    "    accuracy /= num_samples\n",
    "    average_loss /= num_samples\n",
    "    print(f\"Accuracy: {accuracy:<10} Average Loss: {average_loss}\")"
   ],
   "id": "96037e8b5e1f9513",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T21:57:58.611737Z",
     "start_time": "2025-02-06T21:57:56.832617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create training set and test set\n",
    "datagen = DatasetGenerator(lambda x, y: int(x * math.sin(x) - y * math.cos(y) > 0))\n",
    "training_set = list(datagen.generate_samples(1000000))\n",
    "test_set = list(datagen.generate_samples(10000))"
   ],
   "id": "4be4a2c187a67558",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T21:57:58.623510Z",
     "start_time": "2025-02-06T21:57:58.621211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define network\n",
    "dims = [2, 4, 1]\n",
    "weights = []\n",
    "biases = []\n",
    "for i in range(len(dims) - 1):\n",
    "    num_neurons = dims[i + 1]\n",
    "    num_weights = dims[i]\n",
    "    weights.append(np.random.randn(num_neurons, num_weights))\n",
    "    biases.append(np.random.randn(num_neurons, 1))\n",
    "\n",
    "for w, b in zip(weights, biases):\n",
    "    print(w)\n",
    "    print(b)\n",
    "    print()"
   ],
   "id": "ab7b0748aab75d5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.61544505 -0.38541298]\n",
      " [-0.35821369  0.16793369]\n",
      " [-0.4509148   1.06172597]\n",
      " [-0.15527853 -0.38658605]]\n",
      "[[ 0.35723153]\n",
      " [ 0.7538094 ]\n",
      " [-0.04083964]\n",
      " [ 0.37778557]]\n",
      "\n",
      "[[ 1.13396981 -1.61204574  0.0072791  -1.19017144]]\n",
      "[[-1.45410721]]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T21:57:58.735265Z",
     "start_time": "2025-02-06T21:57:58.629080Z"
    }
   },
   "cell_type": "code",
   "source": "validate(test_set)",
   "id": "e3ce6d9491f9be3a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2309     Average Loss: [[0.33275963]]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:41:41.732669Z",
     "start_time": "2025-02-06T22:41:41.728628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create batch of samples\n",
    "batch_size = 32\n",
    "x = training_set[0]['data']\n",
    "y_true = training_set[0]['label']\n",
    "for i in range(1, batch_size):\n",
    "    x = np.hstack((x, training_set[i]['data']))\n",
    "    y_true = np.hstack((y_true, training_set[i]['label']))\n",
    "\n",
    "print(x)\n",
    "print(y_true)"
   ],
   "id": "e01c407afcf78dc3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.94132473  0.9117128  -0.4748528   0.74725123 -0.25882162  0.46913891\n",
      "   1.1521934  -1.19185979  1.22383366 -0.65380156  1.60000012  0.48180448\n",
      "  -2.01483311 -1.11980221 -0.58649699  0.19211943  0.77018437 -0.65301071\n",
      "  -1.76795152 -0.9865179  -0.53597313 -1.39069752  1.00929053  0.12180956\n",
      "   0.93437111  1.61649554  2.12334997  1.29407906  0.85938419 -1.11560809\n",
      "   1.55410494  0.58235799]\n",
      " [-0.03929301 -0.36040814  0.2494835  -0.45123034  1.50338661  1.00678884\n",
      "   0.60362785 -2.17833247 -0.83910535  1.22588032  0.08397148 -0.51184758\n",
      "   0.55234493  0.01815235 -0.91062511  0.86878257 -0.6000085   1.01608405\n",
      "   0.06335135  0.79473105 -1.72252067  1.21072293  0.15316771 -0.55107546\n",
      "   0.3884342   0.61158082 -0.23693186  0.65327687  0.24903584  0.11527263\n",
      "  -2.23069625  0.75967236]]\n",
      "[[1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0]]\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:41:43.558810Z",
     "start_time": "2025-02-06T22:41:43.552837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# feed forward sample\n",
    "z = [None]\n",
    "a = [x]\n",
    "for i, (w, b) in enumerate(zip(weights, biases)):\n",
    "    z.append(w @ a[i] + b)  # weighted sum\n",
    "    a.append(sigma(z[i + 1]))  # activation\n",
    "\n",
    "for z_i, a_i in zip(z, a):\n",
    "    print(z_i)\n",
    "    print(a_i)\n",
    "    print()"
   ],
   "id": "368e1b919f4d021f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[[ 0.94132473  0.9117128  -0.4748528   0.74725123 -0.25882162  0.46913891\n",
      "   1.1521934  -1.19185979  1.22383366 -0.65380156  1.60000012  0.48180448\n",
      "  -2.01483311 -1.11980221 -0.58649699  0.19211943  0.77018437 -0.65301071\n",
      "  -1.76795152 -0.9865179  -0.53597313 -1.39069752  1.00929053  0.12180956\n",
      "   0.93437111  1.61649554  2.12334997  1.29407906  0.85938419 -1.11560809\n",
      "   1.55410494  0.58235799]\n",
      " [-0.03929301 -0.36040814  0.2494835  -0.45123034  1.50338661  1.00678884\n",
      "   0.60362785 -2.17833247 -0.83910535  1.22588032  0.08397148 -0.51184758\n",
      "   0.55234493  0.01815235 -0.91062511  0.86878257 -0.6000085   1.01608405\n",
      "   0.06335135  0.79473105 -1.72252067  1.21072293  0.15316771 -0.55107546\n",
      "   0.3884342   0.61158082 -0.23693186  0.65327687  0.24903584  0.11527263\n",
      "  -2.23069625  0.75967236]]\n",
      "\n",
      "[[-0.20695808 -0.06497162  0.55332316  0.07124949 -0.0629027  -0.31952718\n",
      "  -0.5845262   1.93031335 -0.07256874  0.28714028 -0.65984432  0.25798005\n",
      "   1.3843697   1.03941211  1.06915494 -0.0958475   0.11447644  0.36751176\n",
      "   1.42089212  0.65807943  1.35097537  0.74650111 -0.32296415  0.49465608\n",
      "  -0.36753013 -0.87334383 -0.85825708 -0.69098441 -0.26765386  0.99939945\n",
      "   0.26050463 -0.2939654 ]\n",
      " [ 0.41001538  0.36669673  0.96580486  0.41035701  1.09899212  0.75483119\n",
      "   0.44244741  0.81493447  0.17450137  1.19387668  0.1947691   0.49526399\n",
      "   1.56830752  1.15798627  0.81097601  0.83088746  0.37715718  1.15836153\n",
      "   1.39775266  1.24065574  0.65653306  1.45529746  0.41798974  0.61763141\n",
      "   0.48433607  0.2774636  -0.04659246  0.39995977  0.48778773  1.17279365\n",
      "  -0.17750132  0.67277538]\n",
      " [-0.5070153  -0.83459911  0.43816163 -0.85686925  1.67205147  0.81655254\n",
      "   0.08050667 -1.81620459 -1.4835843   1.55551813 -0.67314868 -0.80153428\n",
      "   1.45411738  0.48336857 -0.7432138   0.79493988 -1.02517178  1.33241538\n",
      "   0.82361763  1.24778247 -1.62800635  1.87170243 -0.33332155 -0.68085651\n",
      "  -0.04975072 -0.12041016 -1.24984628  0.06924198 -0.16394087  0.5845925\n",
      "  -3.1099967   0.5031304 ]\n",
      " [ 0.24680817  0.3755449   0.35507318  0.43619285 -0.16321327 -0.08427215\n",
      "  -0.03447944  1.40496875  0.5121369   0.00539869  0.0968777   0.50084481\n",
      "   0.47711706  0.54464937  0.82089093  0.01209433  0.49014739  0.0863802\n",
      "   0.62781975  0.22373869  1.12691315  0.12568245  0.16185192  0.57190925\n",
      "   0.08253455 -0.1096501   0.13966946 -0.07570485  0.14806787  0.50645277\n",
      "   0.99882248 -0.00632086]]\n",
      "[[0.44844437 0.48376281 0.63490625 0.51780484 0.48427951 0.42079098\n",
      "  0.35789178 0.8732841  0.48186577 0.57129588 0.34077458 0.56413968\n",
      "  0.79969188 0.73873656 0.74443618 0.47605645 0.5285879  0.5908576\n",
      "  0.80547823 0.65882883 0.79428904 0.67841583 0.41995353 0.62120267\n",
      "  0.40913796 0.294559   0.29770362 0.33381412 0.43348316 0.73094049\n",
      "  0.56476034 0.42703335]\n",
      " [0.60109157 0.59066055 0.72428253 0.60117348 0.75007121 0.68023048\n",
      "  0.60884205 0.69316001 0.54351498 0.76743369 0.54853893 0.62134571\n",
      "  0.8275422  0.76096662 0.69231745 0.69654255 0.59318727 0.76103487\n",
      "  0.80182703 0.77567813 0.65848116 0.81081238 0.60300211 0.64967966\n",
      "  0.61877125 0.56892428 0.48835399 0.59867799 0.61958514 0.76364961\n",
      "  0.45574082 0.66212434]\n",
      " [0.37589347 0.30267349 0.6078209  0.29799386 0.84184914 0.69350405\n",
      "  0.5201158  0.13988992 0.18488664 0.82570929 0.33779216 0.30969742\n",
      "  0.81063129 0.618543   0.32230177 0.68889103 0.26402123 0.79123989\n",
      "  0.69500372 0.77691576 0.16410365 0.86665514 0.41743266 0.33607017\n",
      "  0.48756488 0.46993378 0.22272675 0.51730358 0.45910633 0.64212345\n",
      "  0.04269678 0.6231947 ]\n",
      " [0.56139073 0.59279814 0.58784727 0.60735149 0.45928702 0.47894442\n",
      "  0.49138099 0.80297117 0.62530728 0.50134967 0.5242005  0.62265784\n",
      "  0.61706688 0.63289332 0.69442543 0.50302355 0.62014115 0.52158163\n",
      "  0.65199493 0.5557025  0.75526878 0.53137932 0.54037488 0.63920361\n",
      "  0.52062193 0.47261491 0.53486071 0.48108282 0.53694949 0.62397455\n",
      "  0.730827   0.49841979]]\n",
      "\n",
      "[[-2.57998699 -2.56103485 -2.59693391 -2.55673457 -2.65460036 -2.63848348\n",
      "  -2.61079162 -2.53589014 -2.52673404 -2.63409478 -2.57337861 -2.55484282\n",
      "  -2.60983136 -2.59186437 -2.5501257  -2.63080176 -2.54710195 -2.6259276\n",
      "  -2.6042278  -2.61316984 -2.51261397 -2.6179948  -2.59005979 -2.55531106\n",
      "  -2.603725   -2.59629024 -2.53872396 -2.60947392 -2.59707005 -2.59424348\n",
      "  -2.41785971 -2.62590771]]\n",
      "[[0.07043758 0.07168864 0.06933601 0.07197535 0.06570603 0.06670238\n",
      "  0.06844711 0.07338014 0.07400515 0.06697611 0.0708715  0.07210181\n",
      "  0.06850836 0.06966385 0.07241804 0.06718219 0.07262142 0.06748829\n",
      "  0.06886682 0.06829563 0.07497861 0.06798925 0.0697809  0.07207049\n",
      "  0.06889907 0.06937756 0.07318768 0.06853118 0.06932723 0.06950982\n",
      "  0.0818209  0.06748954]]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:41:50.880880Z",
     "start_time": "2025-02-06T22:41:50.874996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# backpropagate sample\n",
    "eta = 1\n",
    "\n",
    "delta_weights = []\n",
    "delta_biases = []\n",
    "\n",
    "gradient_i = loss_prime(y_true, a[-1])\n",
    "for i in range(1, len(weights) + 1):\n",
    "    if i == 1:\n",
    "        w_i = np.identity(gradient_i.shape[0])\n",
    "    else:\n",
    "        w_i = weights[-i + 1].T\n",
    "\n",
    "    gradient_i = (w_i @ gradient_i) * sigma_prime(z[-i])\n",
    "    weight_gradient_i = gradient_i @ a[-i - 1].T\n",
    "    bias_gradient_i = gradient_i @ np.ones((batch_size, 1))\n",
    "\n",
    "    print(f\"weights {i}:\\t\\t {w_i.shape}\")\n",
    "    print(f\"sigma_prime {i}:\\t {sigma_prime(z[-i]).shape}\")\n",
    "    print(f\"gradient {i}:\\t\\t {gradient_i.shape}\")\n",
    "    print(f\"activation {i - 1}:\\t {a[-i - 1].T.shape}\")\n",
    "    print()\n",
    "\n",
    "    delta_weights.append(eta * weight_gradient_i)\n",
    "    delta_biases.append(eta * bias_gradient_i)\n",
    "\n",
    "for dw, db in zip(delta_weights, delta_biases):\n",
    "    print(dw)\n",
    "    print(db)\n",
    "    print()"
   ],
   "id": "5e0a88b53d120db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights 1:\t\t (1, 1)\n",
      "sigma_prime 1:\t (1, 32)\n",
      "gradient 1:\t\t (1, 32)\n",
      "activation 0:\t (32, 4)\n",
      "\n",
      "weights 2:\t\t (4, 1)\n",
      "sigma_prime 2:\t (4, 32)\n",
      "gradient 2:\t\t (4, 32)\n",
      "activation 1:\t (32, 2)\n",
      "\n",
      "[[-0.78060734 -0.91641311 -0.60917308 -0.85178748]]\n",
      "[[-1.43671133]]\n",
      "\n",
      "[[-1.66090281e-01  6.37159851e-02]\n",
      " [ 2.67562003e-01 -1.07819876e-01]\n",
      " [-8.16738708e-04  1.17011870e-04]\n",
      " [ 1.51471501e-01 -4.76918803e-02]]\n",
      "[[-0.36001047]\n",
      " [ 0.51210971]\n",
      " [-0.00210154]\n",
      " [ 0.4036404 ]]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 38
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
