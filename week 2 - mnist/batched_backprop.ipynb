{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T22:33:16.942021Z",
     "start_time": "2025-02-13T22:33:16.938413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from src.datagen import DatasetGenerator"
   ],
   "id": "8439de0eac0b66da",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T22:33:18.461244Z",
     "start_time": "2025-02-13T22:33:18.458799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define activation function\n",
    "def sigma(z):\n",
    "    return 1 / (1 + np.e**(-z)) # sigmoid\n",
    "\n",
    "def sigma_prime(z):\n",
    "    y = sigma(z)\n",
    "    return y * (1 - y)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T22:31:28.968848Z",
     "start_time": "2025-02-13T22:31:28.967044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define loss function\n",
    "def loss(y_true, y_pred):\n",
    "    return (y_true - y_pred)**2 / 2 # squared error loss\n",
    "\n",
    "def loss_prime(y_true, y_pred):\n",
    "    return -(y_true - y_pred) # squared error loss"
   ],
   "id": "fd13186d1e006e7e",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T22:31:28.974904Z",
     "start_time": "2025-02-13T22:31:28.972523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define training routine\n",
    "def train(training_set, batch_size=32, epochs=10, eta=0.01, validation_set=None):\n",
    "    for sample in training_set:\n",
    "        # read sample\n",
    "        x = sample['data']\n",
    "        y_true = sample['label']\n",
    "\n",
    "        # feed forward\n",
    "        z = [np.empty(0)]\n",
    "        a = [x]\n",
    "        for i, (w, b) in enumerate(zip(weights, biases)):\n",
    "            z.append(w @ a[i] + b)  # weighted sum\n",
    "            a.append(sigma(z[i + 1]))  # activation\n",
    "\n",
    "        # backpropagate\n",
    "        gradient_i = loss_prime(y_true, a[-1])\n",
    "        for i in range(1, len(weights) + 1):\n",
    "            if i == 1:\n",
    "                w_i = np.identity(gradient_i.shape[0])\n",
    "            else:\n",
    "                w_i = weights[-i + 1].T\n",
    "\n",
    "            gradient_i = (w_i @ gradient_i) * sigma_prime(z[-i])\n",
    "            weight_gradient_i = gradient_i @ a[-i - 1].T\n",
    "            weights[-i] -= eta * weight_gradient_i\n",
    "            biases[-i] -= eta * gradient_i"
   ],
   "id": "8e3589a5c78056ef",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T22:31:28.980516Z",
     "start_time": "2025-02-13T22:31:28.978201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define validation routine\n",
    "def feed_forward(x):\n",
    "    for w, b in zip(weights, biases):\n",
    "        z = w @ x + b  # weighted sum\n",
    "        y = sigma(z)  # activation\n",
    "        x = y  # output of this layer is input of the next\n",
    "    return x\n",
    "\n",
    "def validate(validation_set, verbose=False, print_samples=10):\n",
    "    average_loss = 0\n",
    "    accuracy = 0\n",
    "    num_samples = 0\n",
    "    for sample in validation_set:\n",
    "        x = sample['data']\n",
    "        y_pred = feed_forward(x)\n",
    "        y_true = sample['label']\n",
    "\n",
    "        sample_loss = loss(y_true, y_pred)\n",
    "\n",
    "        num_samples += 1\n",
    "        average_loss += sample_loss\n",
    "        if np.array_equal(np.round(y_pred), y_true):\n",
    "            accuracy += 1\n",
    "\n",
    "    accuracy /= num_samples\n",
    "    average_loss /= num_samples\n",
    "    print(f\"Accuracy: {accuracy:<10} Average Loss: {average_loss}\")"
   ],
   "id": "96037e8b5e1f9513",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T22:33:23.450331Z",
     "start_time": "2025-02-13T22:33:21.577682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create training set and test set\n",
    "datagen = DatasetGenerator(lambda x, y: int(x * math.sin(x) - y * math.cos(y) > 0))\n",
    "training_set = list(datagen.generate_samples(1000000))\n",
    "test_set = list(datagen.generate_samples(10000))"
   ],
   "id": "4be4a2c187a67558",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T22:33:25.070226Z",
     "start_time": "2025-02-13T22:33:25.065950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define network\n",
    "dims = [2, 4, 1]\n",
    "weights = []\n",
    "biases = []\n",
    "for i in range(len(dims) - 1):\n",
    "    num_neurons = dims[i + 1]\n",
    "    num_weights = dims[i]\n",
    "    weights.append(np.random.randn(num_neurons, num_weights))\n",
    "    biases.append(np.random.randn(num_neurons, 1))\n",
    "\n",
    "for w, b in zip(weights, biases):\n",
    "    print(w)\n",
    "    print(b)\n",
    "    print()"
   ],
   "id": "ab7b0748aab75d5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.25598582  0.07432802]\n",
      " [-1.24015528  0.22935381]\n",
      " [-0.87693144 -0.04319777]\n",
      " [ 0.64505426  0.08628289]]\n",
      "[[1.47220724]\n",
      " [0.83315479]\n",
      " [0.26152609]\n",
      " [0.48671254]]\n",
      "\n",
      "[[ 0.62086154  1.73202972 -0.34463041 -1.91601346]]\n",
      "[[-0.01202509]]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T22:33:27.159854Z",
     "start_time": "2025-02-13T22:33:27.027588Z"
    }
   },
   "cell_type": "code",
   "source": "validate(test_set)",
   "id": "e3ce6d9491f9be3a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5055     Average Loss: [[0.12363905]]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T22:33:28.634351Z",
     "start_time": "2025-02-13T22:33:28.629956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create batch of samples\n",
    "batch_size = 32\n",
    "x = training_set[0]['data']\n",
    "y_true = training_set[0]['label']\n",
    "for i in range(1, batch_size):\n",
    "    x = np.hstack((x, training_set[i]['data']))\n",
    "    y_true = np.hstack((y_true, training_set[i]['label']))\n",
    "\n",
    "print(x)\n",
    "print(y_true)"
   ],
   "id": "e01c407afcf78dc3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.08286058 -0.16561444  0.81325145 -0.38318923 -0.93427263  0.67678388\n",
      "  -0.25942844 -1.20406114 -1.40323003 -0.282881   -0.7878895   0.19245011\n",
      "  -0.13678735  1.27363488  1.13478781 -0.01599958  0.31650258 -2.26735391\n",
      "   1.01470395 -0.40771864  0.16582471  1.68481218  0.11313136 -1.16435185\n",
      "   0.58753389 -0.77435293  0.70944193 -1.13715183 -0.51459813 -0.44463346\n",
      "  -0.17175865 -0.02177528]\n",
      " [ 1.23209888 -1.34995484 -0.44609543  0.7712027  -0.35683213 -0.13805914\n",
      "   0.85229779 -0.01283679 -1.38929679 -0.32422991 -0.04629461 -0.20362991\n",
      "  -0.19902883  0.74259767 -0.21765863 -0.81597707  0.47038889 -0.30139455\n",
      "   0.32267048  0.52131731  1.45329427  1.06753956 -1.18077247  0.25586608\n",
      "   0.1613435   0.62978426 -0.78952235  0.27100745 -0.63661874 -1.26228822\n",
      "  -0.76584267 -1.71169478]]\n",
      "[[0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0]]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T22:33:30.473448Z",
     "start_time": "2025-02-13T22:33:30.468368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# feed forward sample\n",
    "z = [None]\n",
    "a = [x]\n",
    "for i, (w, b) in enumerate(zip(weights, biases)):\n",
    "    z.append(w @ a[i] + b)  # weighted sum\n",
    "    a.append(sigma(z[i + 1]))  # activation\n",
    "\n",
    "for z_i, a_i in zip(z, a):\n",
    "    print(z_i)\n",
    "    print(a_i)\n",
    "    print()"
   ],
   "id": "368e1b919f4d021f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[[-0.08286058 -0.16561444  0.81325145 -0.38318923 -0.93427263  0.67678388\n",
      "  -0.25942844 -1.20406114 -1.40323003 -0.282881   -0.7878895   0.19245011\n",
      "  -0.13678735  1.27363488  1.13478781 -0.01599958  0.31650258 -2.26735391\n",
      "   1.01470395 -0.40771864  0.16582471  1.68481218  0.11313136 -1.16435185\n",
      "   0.58753389 -0.77435293  0.70944193 -1.13715183 -0.51459813 -0.44463346\n",
      "  -0.17175865 -0.02177528]\n",
      " [ 1.23209888 -1.34995484 -0.44609543  0.7712027  -0.35683213 -0.13805914\n",
      "   0.85229779 -0.01283679 -1.38929679 -0.32422991 -0.04629461 -0.20362991\n",
      "  -0.19902883  0.74259767 -0.21765863 -0.81597707  0.47038889 -0.30139455\n",
      "   0.32267048  0.52131731  1.45329427  1.06753956 -1.18077247  0.25586608\n",
      "   0.1613435   0.62978426 -0.78952235  0.27100745 -0.63661874 -1.26228822\n",
      "  -0.76584267 -1.71169478]]\n",
      "\n",
      "[[ 1.58499785  1.41426272  1.23086902  1.62762022  1.68484516  1.28869851\n",
      "   1.60196685  1.77947569  1.72815055  1.5205214   1.6704548   1.40780734\n",
      "   1.49242945  1.20137059  1.16553952  1.41565295  1.42615015  2.03021563\n",
      "   1.23644088  1.61532592  1.53777895  1.12026732  1.35548274  1.78928282\n",
      "   1.33379924  1.71724123  1.23191654  1.78344543  1.55661846  1.49220372\n",
      "   1.45925145  1.35055453]\n",
      " [ 1.21850135  0.72892513 -0.27771697  1.48524722  1.90995712 -0.03782671\n",
      "   1.35036409  2.32343341  2.25473742  1.10960779  1.79964227  0.54778348\n",
      "   0.95714433 -0.57603263 -0.62407914  0.66584931  0.54852793  3.57589973\n",
      "  -0.35122997  1.45835532  0.96082498 -1.01142967  0.42203967  2.33581575\n",
      "   0.14152628  1.93791609 -0.22774332  2.30555622  1.32532545  1.09505871\n",
      "   0.87051326  0.46757581]\n",
      " [ 0.28096521  0.46507364 -0.43236934  0.56424254  1.09623348 -0.32600312\n",
      "   0.45220968  1.31795968  1.55207714  0.52359934  0.95445098  0.1015569\n",
      "   0.39007682 -0.88744294 -0.72420265  0.31080502 -0.03634472  2.26285958\n",
      "  -0.64223835  0.59654764  0.05333012 -1.262054    0.21332438  1.27152999\n",
      "  -0.26067053  0.91337525 -0.32650023  1.24702336  0.74029388  0.70596719\n",
      "   0.44522935  0.35456292]\n",
      " [ 0.53957202  0.26340423  0.97281345  0.30607629 -0.14673252  0.91136272\n",
      "   0.39290583 -0.29107983 -0.53831952  0.27626345 -0.02551337  0.59328352\n",
      "   0.38130449  1.37234962  1.19993204  0.40598707  0.73146039 -1.00185896\n",
      "   1.16909259  0.26869266  0.71907291  1.66561822  0.45780794 -0.24228072\n",
      "   0.87962496  0.04155248  0.8762188  -0.22342879  0.09983951  0.09098595\n",
      "   0.30983977  0.32497632]]\n",
      "[[0.82991117 0.80443742 0.77397064 0.83584337 0.84354505 0.78392682\n",
      "  0.8322931  0.85563211 0.8491757  0.82061525 0.84163645 0.80341987\n",
      "  0.81644264 0.76876851 0.76233782 0.80465603 0.80630076 0.8839332\n",
      "  0.77494389 0.83414951 0.82314162 0.7540383  0.79502454 0.85683933\n",
      "  0.79146838 0.84777315 0.77415384 0.85612179 0.82586759 0.81640881\n",
      "  0.81141816 0.79422027]\n",
      " [0.77179971 0.67456935 0.43101358 0.81536383 0.87101433 0.49054445\n",
      "  0.79418915 0.91079928 0.90505839 0.75205598 0.85810538 0.63362119\n",
      "  0.72254969 0.35984599 0.34885428 0.66057313 0.63379399 0.97277189\n",
      "  0.41308419 0.811281   0.72328695 0.26670016 0.60397122 0.91180016\n",
      "  0.53532263 0.87412303 0.44330899 0.90933616 0.79006636 0.74933311\n",
      "  0.70485248 0.61480982]\n",
      " [0.56978284 0.61421709 0.3935607  0.63743361 0.74955371 0.41921344\n",
      "  0.61116448 0.78884205 0.82521353 0.62798903 0.72200943 0.52536743\n",
      "  0.59630119 0.2916378  0.3264682  0.57708175 0.49091482 0.90575402\n",
      "  0.34474073 0.64486606 0.51332937 0.22062051 0.55312977 0.78100454\n",
      "  0.43519889 0.71369035 0.41909241 0.77678416 0.67706012 0.66950944\n",
      "  0.60950437 0.58772364]\n",
      " [0.63171285 0.56547294 0.72567992 0.57592724 0.46338255 0.71327894\n",
      "  0.59698202 0.42773953 0.36857859 0.56862992 0.493622   0.64411818\n",
      "  0.59418769 0.79775951 0.76851269 0.60012527 0.67512566 0.26857608\n",
      "  0.76298096 0.56677193 0.67240283 0.84099074 0.61249403 0.43972438\n",
      "  0.7067445  0.51038663 0.70603805 0.44437402 0.52493917 0.52273081\n",
      "  0.57684615 0.58053654]]\n",
      "\n",
      "[[ 0.43328004  0.36066168 -0.31101364  0.59598896  0.87415609 -0.18680325\n",
      "   0.52582143  1.00532175  1.09218826  0.49411997  0.80216583  0.16904144\n",
      "   0.40237514 -0.54048753 -0.5194844   0.28295918  0.12359204  1.39489909\n",
      "  -0.39610807  0.60284596  0.28654459 -0.76932123  0.16349904  0.98754273\n",
      "  -0.09755284  0.80446467 -0.2607688   0.97537521  0.63001673  0.56042638\n",
      "   0.39727996  0.23108136]]\n",
      "[[0.60665664 0.5892006  0.42286734 0.64473811 0.70560976 0.45343452\n",
      "  0.628508   0.73210361 0.74879356 0.62107651 0.69043758 0.54216001\n",
      "  0.59925818 0.36807418 0.37297281 0.57027156 0.53085874 0.8013732\n",
      "  0.40224778 0.64630715 0.57114998 0.31662596 0.54078395 0.72860229\n",
      "  0.47563111 0.69092871 0.43517473 0.72618959 0.65249326 0.63655119\n",
      "  0.59803397 0.55751463]]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T22:33:31.823519Z",
     "start_time": "2025-02-13T22:33:31.818378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# backpropagate sample\n",
    "eta = 1\n",
    "\n",
    "delta_weights = []\n",
    "delta_biases = []\n",
    "\n",
    "gradient_i = loss_prime(y_true, a[-1])\n",
    "for i in range(1, len(weights) + 1):\n",
    "    if i == 1:\n",
    "        w_i = np.identity(gradient_i.shape[0])\n",
    "    else:\n",
    "        w_i = weights[-i + 1].T\n",
    "\n",
    "    gradient_i = (w_i @ gradient_i) * sigma_prime(z[-i])\n",
    "    weight_gradient_i = gradient_i @ a[-i - 1].T\n",
    "    bias_gradient_i = gradient_i @ np.ones((batch_size, 1))\n",
    "\n",
    "    print(f\"weights {i}:\\t\\t {w_i.shape}\")\n",
    "    print(f\"sigma_prime {i}:\\t {sigma_prime(z[-i]).shape}\")\n",
    "    print(f\"gradient {i}:\\t\\t {gradient_i.shape}\")\n",
    "    print(f\"activation {i - 1}:\\t {a[-i - 1].T.shape}\")\n",
    "    print()\n",
    "\n",
    "    delta_weights.append(eta * weight_gradient_i)\n",
    "    delta_biases.append(eta * bias_gradient_i)\n",
    "\n",
    "for dw, db in zip(delta_weights, delta_biases):\n",
    "    print(dw)\n",
    "    print(db)\n",
    "    print()"
   ],
   "id": "5e0a88b53d120db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights 1:\t\t (1, 1)\n",
      "sigma_prime 1:\t (1, 32)\n",
      "gradient 1:\t\t (1, 32)\n",
      "activation 0:\t (32, 4)\n",
      "\n",
      "weights 2:\t\t (4, 1)\n",
      "sigma_prime 2:\t (4, 32)\n",
      "gradient 2:\t\t (4, 32)\n",
      "activation 1:\t (32, 2)\n",
      "\n",
      "[[-1.13333085 -0.71853021 -0.68165152 -0.94451327]]\n",
      "[[-1.44475018]]\n",
      "\n",
      "[[-0.08519533  0.09579633]\n",
      " [-0.36412144  0.35181175]\n",
      " [ 0.05576336 -0.09358951]\n",
      " [ 0.15232484 -0.53345559]]\n",
      "[[-0.15086828]\n",
      " [-0.52770717]\n",
      " [ 0.10240861]\n",
      " [ 0.55502445]]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
